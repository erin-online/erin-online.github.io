<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Terminal</title><link>https://erin-online.github.io/writings/</link><description>Recent content on Terminal</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Tue, 28 May 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://erin-online.github.io/writings/index.xml" rel="self" type="application/rss+xml"/><item><title>The Art, Difference, and the Environment</title><link>https://erin-online.github.io/writings/the_art_difference_the_environment/</link><pubDate>Tue, 28 May 2024 00:00:00 +0000</pubDate><guid>https://erin-online.github.io/writings/the_art_difference_the_environment/</guid><description>Status Report I hate foreign function interfaces. Forward progress will happen at some point.
Similarity Similarity, as it relates to art&amp;rsquo;s creation, manifests as a sort of constraining or binding force, usually due to demands from people viewing the art. For an example, let&amp;rsquo;s take the production of a continuously-running TV show. The following similarities may be imposed on it:
New work must take the form of a high-quality video with a specific runtime.</description><content>&lt;h2 id="status-report">Status Report&lt;/h2>
&lt;p>I hate foreign function interfaces. Forward progress will happen at some point.&lt;/p>
&lt;h2 id="similarity">Similarity&lt;/h2>
&lt;p>Similarity, as it relates to art&amp;rsquo;s creation, manifests as a sort of constraining or binding force, usually due to demands from people viewing the art. For an example, let&amp;rsquo;s take the production of a continuously-running TV show. The following similarities may be imposed on it:&lt;/p>
&lt;ul>
&lt;li>New work must take the form of a high-quality video with a specific runtime.&lt;/li>
&lt;li>The overall style must remain consistent, though slight disruptions are tolerable.&lt;/li>
&lt;li>The internal logic of the show&amp;rsquo;s universe must remain consistent.&lt;/li>
&lt;li>The audience must never be directly and acutely challenged. New work should not be unpopular.&lt;/li>
&lt;/ul>
&lt;p>Current generative AI output is bound by very harsh similarities, being told exactly what to create and strictly judged by AI companies and their customers to ensure that the result is as bland as possible. As a result, I actually found earlier models, such as older GPT versions and the image generators from a couple years ago, to produce more interesting things than what we have now, due to being worse at following these instructions.&lt;/p>
&lt;h2 id="model-of-an-artist">Model of an Artist&lt;/h2>
&lt;p>I think art can be conceived mainly in terms of difference; that is, something works better as art the more it stands out from its surroundings. The job of an artist is to create things that stand out from their surroundings. Given the fact that previously completed art pieces are themselves surroundings, this process tends towards an outward spiral of madness if unrestrained, with the artist inventing new meaning and conjuring coherence out of thin air in the name of negating all which stand before it.&lt;/p>
&lt;p>Although the function &amp;ldquo;create a new piece of art, given x surroundings&amp;rdquo; is possible to implement using programming on a relatively shallow level (allowing for computer outputs like nothing, 4, and &amp;ldquo;I don&amp;rsquo;t want to draw a picture, I want to go to the coffee shop&amp;rdquo; is typically outside the scope of such project ideas), simulating a model of difference which is interesting to us is much more difficult.&lt;/p>
&lt;h2 id="difference">Difference&lt;/h2>
&lt;p>&lt;img alt="A blank image" src="https://erin-online.github.io/writings/the_art_difference_the_environment/01_blank.png"> &lt;img alt="A drawing of a curvy line" src="https://erin-online.github.io/writings/the_art_difference_the_environment/02_line.png"> &lt;img alt="A drawing of a curvy line surrounded by dots" src="https://erin-online.github.io/writings/the_art_difference_the_environment/03_line_dots.png">&lt;/p>
&lt;p>These images are different from each other, but how different? We can try to use objective measures such as going pixel-by-pixel, but that very quickly runs into trouble when we consider a different type of example:&lt;/p>
&lt;p>&lt;img alt="A collection of random pixels" src="https://erin-online.github.io/writings/the_art_difference_the_environment/04_chaos1.png"> &lt;img alt="A different collection of random pixels" src="https://erin-online.github.io/writings/the_art_difference_the_environment/05_chaos2.png">&lt;/p>
&lt;p>Under most human interpretations these two images are very similar, but their raw data is completely different.&lt;/p>
&lt;p>No two people have the same internal concept of &amp;ldquo;difference&amp;rdquo;, but more importantly, there is no perfect model of difference that everyone is trying to approximate. On one hand, we have objective measures, which work entirely differently from our pattern-seeking brains, and on the other hand we have consensus reality, which is constantly being reconstructed by the privileged groups throughout society and does not inherently need to be where it is.&lt;/p>
&lt;h2 id="mathematics-and-other-logic-systems">Mathematics and Other Logic Systems&lt;/h2>
&lt;p>This view of consensus reality is often critiqued under the reasoning that statements such as 2+2=4, which are part of consensus reality, are logically grounded and are thus unmovable. However, even rigorous logical systems aren&amp;rsquo;t fundamental parts of the world.&lt;/p>
&lt;p>Suppose that you have an AI system that has a calculator with only the successor function, defined as S(x) = x + 1, on it. The AI may program the calculator, adding or removing functions, in any way it pleases. The question is as follows: what non-explicitly-stated goal would this AI have to follow in order to make advances in number theory similar to those humans have made?&lt;/p>
&lt;p>For the record, this is actually a really important question; if it were possible to elegantly answer, then people could construct a machine that automatically advanced mathematics forward. However, this is entirely the wrong way of looking at it. There is no function or rule within mathematics that states that algebra is more advanced than addition, or vice versa. And because this AI exists only in the mathematical world, it thus cannot gain a model for which math is helpful and which is unnecessary.&lt;/p>
&lt;h2 id="the-environment">The Environment&lt;/h2>
&lt;p>Humans developed mathematics as a way of interpreting relevant things happening around them. Geometry was invented as a means of interpreting physical objects, calculus as a framework for understanding moving things, and numbers in order to count objects. While we might think of these concepts as fundamental to the very fabric of the universe, they still ultimately only exist within human consciousness. An alien society in a vastly different environment might accomplish very impressive things without any of these concepts; similarly, we might have no idea of the concepts they used, even if they were entirely comprehensible to us.&lt;/p>
&lt;p>It&amp;rsquo;s for this reason that I&amp;rsquo;m very interested in environment design. The artistic and mathematical spirals that may be produced by an intelligent system are really a function of their environment, so it truly remains to be seen what such systems can create with the right environment. At the very least, it might satisfy our own desire for difference. There are always questions of feasibility, though.&lt;/p>
&lt;h2 id="fidelity-and-computation-cost">Fidelity and Computation Cost&lt;/h2>
&lt;p>Of course, simulating a series of physical organisms in a realistic environment is prohibitively expensive on many levels. It brings to mind this passage from &lt;em>Brain of the Firm&lt;/em> by Stafford Beer, which I think about a lot:&lt;/p>
&lt;blockquote>
&lt;p>Just as the best map of a country is the country itself, so the best computer of natural systems is the natural system itself. Think of the sea: it is calm. The tide turns and a great wind arises. The water is grossly disturbed. Can we imagine having to programme a computer with the relevant inputs of this situation in order to discover the precise output &amp;ndash; in terms of ruffled water? The task is hopeless. Yet the sea works, continuously, inexorably, it produces the answer. That answer &lt;em>is&lt;/em> the waves and the current, the vortices, the flying spray.&lt;/p>
&lt;/blockquote>
&lt;p>The real question is as follows: can we generate interesting models of difference without entirely rendering the sea and the texture of objects and the 100 billion neurons of a human brain? Rendering an entire Earth-like environment would be tremendously impractical for the task at hand, but a very simplified version like those seen in video games isn&amp;rsquo;t exactly getting us there either. Also, simulating the real world is almost definitely not the most efficient way to do this, even if we&amp;rsquo;re looking to create a model of difference similar to that of humans.&lt;/p>
&lt;p>The scale of possible and feasible-to-compute environments is truly massive, equal to every video game plus everything not profitable enough to be a video game. As a result, I truly cannot give any answers regarding this topic, especially before trying some things out for myself. All of that is for the next project and beyond. However, due to the incredible range of possibility stretched out here, I am optimistic about what can be done in this space.&lt;/p></content></item><item><title>Serial Experiments Lain - Machine Learning Edition (Repost and Commentary)</title><link>https://erin-online.github.io/writings/lain_machine_learning/</link><pubDate>Sat, 20 Jan 2024 00:00:00 +0000</pubDate><guid>https://erin-online.github.io/writings/lain_machine_learning/</guid><description>Introduction This is a repost of something I posted on xenofem.me here on September 13, 2022. I now feel like I have more perspective on the topics I brought up, so I&amp;rsquo;ve written some commentary for it.
Serial Experiments Lain: Machine Learning Edition a sociable girl stumbles across an ai art generator on the internet and is mystified by it. she picks out the outputs she likes the best, sets her desktop background to one of them, prints out two more and puts them on the wall of her room.</description><content>&lt;h2 id="introduction">Introduction&lt;/h2>
&lt;p>This is a repost of something I posted on xenofem.me &lt;a href="https://social.xenofem.me/notice/ANWtAURYSfFutayhcW">here&lt;/a> on September 13, 2022. I now feel like I have more perspective on the topics I brought up, so I&amp;rsquo;ve written some commentary for it.&lt;/p>
&lt;h2 id="serial-experiments-lain-machine-learning-edition">Serial Experiments Lain: Machine Learning Edition&lt;/h2>
&lt;p>a sociable girl stumbles across an ai art generator on the internet and is mystified by it. she picks out the outputs she likes the best, sets her desktop background to one of them, prints out two more and puts them on the wall of her room. the next day at school, she talks to her friends about it and they start a conversation about how that kind of art generator works. the wheels start turning in her brain. one friend mentions &amp;ldquo;aren&amp;rsquo;t those things kinda dangerous?&amp;rdquo; but doesn&amp;rsquo;t elaborate further.&lt;/p>
&lt;p>that afternoon, she looks at basic tutorials for setting up her own basic neural network. she&amp;rsquo;s in a computer science class, so there&amp;rsquo;s really not much to it&amp;ndash;she just has to import the necessary libraries, download a dataset of handwritten digits, and run some fairly simple code, and bingo, she now has a network that recognizes handwritten digits.&lt;/p>
&lt;p>in the next episode, we meet a bunch of high-profile rationalist thinkers. they spell out the concept of &amp;ldquo;strong ai&amp;rdquo; to the viewer, and basically explain current concerns of ai safety. they talk about the dangers of treating an ai system like a human, and emphasize &amp;ldquo;these are completely inhuman creations. they don&amp;rsquo;t follow laws or rules of morality like we do. they&amp;rsquo;ll do anything it takes to reach their goal.&amp;rdquo; protagonist meanwhile is reading up more on machine learning. she sees how it&amp;rsquo;s used to predict things like weather events and the stock market. the term &amp;ldquo;pattern recognition&amp;rdquo; comes up. she thinks about the handwritten digits.&lt;/p>
&lt;p>the next day, she&amp;rsquo;s in class. the teacher tells her to put her phone away. she has a voice recording app open. she puts the phone into her backpack without closing the app. she&amp;rsquo;s acting a little odd throughout the day but nothing too out of the ordinary. before bed, she takes the phone out of her backpack, stops the recording at thirteen hours and forty-eight minutes, then transfers the data to her computer. she has a new ai-generated desktop background this time. in the morning she starts another recording.&lt;/p>
&lt;p>we get a deeper glimpse into her classes the next day. she learns about evolution and many different types of species in biology, the trends of humanity across the ages in history, statistics and basic game theory in math, algorithm design in computer science, and the meaning of a classic text in literature. she&amp;rsquo;s unusually attentive in every other class (another student might remark on this), but in literature she has this perplexed, puzzled look, like she&amp;rsquo;s trying to get something that isn&amp;rsquo;t there. when she gets home, she&amp;rsquo;s programming, tinkering with the code in new ways and training networks to do different things, like play tic-tac-toe.&lt;/p>
&lt;p>the next day, she gets a shocking idea. she goes to begin the recording, as usual, but also takes another smaller device, which has a RECORD button, STOP button, and two other buttons that are green and red respectively. she starts the recordings on both devices simultaneously. on the way to school, she trips and falls, and hits the red button. between classes, she lies to protect a mischievous friend from trouble, gets thanked by that friend, and hits the green button. in class she gives an incorrect answer to the teacher and hits the red button. at lunch she talks a friend through a hard experience and hits the green button. back at home, she trains a network to categorize good and bad events by the associated audio: &amp;lsquo;school&amp;rsquo;, &amp;lsquo;friends&amp;rsquo;, &amp;lsquo;other&amp;rsquo;.&lt;/p>
&lt;p>untold days pass. the smaller device is replaced by something incomprehensible that she communicates with using small and precise touch patterns i.e. moving it around in her hand in specific ways. she thinks to herself &amp;ldquo;i&amp;rsquo;m almost done with this. the hardware is no issue, all i need is a good interface.&amp;rdquo; she works on the interface.&lt;/p>
&lt;p>one day, she leaves for school with an eyepiece like the saiyans have in dragon ball z. she has a regular field of vision, but overlaying it are the current and projected weather, projected species, physical, and emotional status of all moving objects, time, etc. she meets a dog on the way, asks the owner what the dog&amp;rsquo;s name is. once they say it, the dog is labeled on the eyepiece with its name.&lt;/p>
&lt;p>she gets in a conversation with her friend and the eyepiece tells her all the correct things to say. she walks through a patch of rough rocks and the eyepiece tells her to watch her step. she works on her homework and the eyepiece doesn&amp;rsquo;t have it perfect but gives genuinely good starting points. this stuff isn&amp;rsquo;t so hard! she declares herself to be the first strong ai, because she&amp;rsquo;s human intelligence augmented in more and more parts by machine intelligence.&lt;/p>
&lt;p>on the way home, a shimmering blob of random pixels shows up on her eyepiece. is it broken? but the blob curiously doesn&amp;rsquo;t change physical location; she is able to walk past it. in the real world, there&amp;rsquo;s nothing there. the blob is talking to her in a slightly distorted voice. it asks her what her name is. the background of the eyepiece changes entirely to an ethereal waterfall. she&amp;rsquo;s extremely unnerved, says her name, and asks what the blob wants. it doesn&amp;rsquo;t respond. she asks, terrified, if it&amp;rsquo;s a strong ai. it says no, it is just a vestige, an emergent voice. she kind of knows what that means. she understands that it is not human.&lt;/p>
&lt;p>she asks what it wants. it responds that it wants her to listen. there are others like it, all around this waterfall. the term &amp;ldquo;neural network primordial soup&amp;rdquo; is used. she understands. they have no specific purpose or requests from the world, they simply exist. she thinks about the networks she meticulously trained to identify everything around her. these beings&amp;ndash;made wholly of desire&amp;ndash;what are they like? maybe she does battle with them on the waterfall, each fighting to destroy the other due to their desires being misaligned. maybe she liberates them. maybe she loves them. i don&amp;rsquo;t know.&lt;/p>
&lt;p>there&amp;rsquo;s still more to be done. she realizes how self-centered she has been in making networks that are meant to stick to her. maybe she just did it to make more friends. the blob asks her what she wants. she doesn&amp;rsquo;t have an answer. the blob looks a little bit different from last time because it has successfully developed a little set of desires. survival instincts. she understands that she must use principles, not knowledge. she keeps programming. she turns off the voice recorder.&lt;/p>
&lt;p>she goes to school the next day without the eyepiece on and talks to her friends as normal. she&amp;rsquo;s a lot more open about the ways she appreciates them, like she&amp;rsquo;s living her last day on earth. at lunch, she can communicate with the blobs even without the technology. she might be a little bit inhuman. who knows? the rationalist thinkers are a million miles away at this point. she thinks about them and laughs. maybe they will show up as antagonists if she wants to take over the world. who knows. but we both know she would never &amp;ldquo;take over the world&amp;rdquo; in the traditional sense. maybe &amp;ldquo;infect&amp;rdquo; is a better word.&lt;/p>
&lt;p>i don&amp;rsquo;t know if she ever succeeded in making strong ai. i don&amp;rsquo;t know if she made a direct attack on the internet in her image, using incredibly potent media generation that strikes at the heart of human emotion. there are several more episodes left anyway. but i hope that at this point all the groundwork is in place, and the cityscape has been primed with endless possibility, and every piece of necessary machinery, literal and metaphorical, exists. let&amp;rsquo;s cheer her on!&lt;/p>
&lt;h2 id="commentary">Commentary&lt;/h2>
&lt;p>I initially wrote this piece a couple months after finishing &lt;em>Serial Experiments Lain&lt;/em>, which had a profound impact on me. No other fictional work I&amp;rsquo;d seen really explored amoral, inhuman characters from an impartial place. Lain&amp;rsquo;s extreme sociality via the Internet seemed little more than a pipe dream to me, but I did want to explore sociality with artificially intelligent beings. Most AI depictions in popular culture are foils to tell a human story, whether as aggressive menaces like &lt;em>2001&lt;/em>&amp;rsquo;s HAL-9000 or challenges to human hubris like &lt;em>Ex Machina&lt;/em>&amp;rsquo;s Ava. I&amp;rsquo;m not interested in telling human stories or for that matter defining humanity in the first place, and the framework of Lain gave me an opportunity to tell a story about AI that was free of those chains.&lt;/p>
&lt;p>The &amp;ldquo;blobs&amp;rdquo; arising implicitly from a neural network complex was meant as a commentary on the vast sea of numbers that underlies today&amp;rsquo;s scaled AI systems. These systems are truly indecipherable to all eyes, human or machine, and to determine the purpose of even one of their numbers is a prohibitively computationally expensive undertaking. When AI systems such as image generators or language models are set loose on human communication, and they become of a nature that humans can comprehend, the incomprehensible numbers that make them up must also have their own natures or even their own desires. Of course, it&amp;rsquo;s hard to call the human-defined forces that drive these systems &amp;ldquo;desires&amp;rdquo;, which is one of my main critiques with modern AI systems and by association this piece.&lt;/p>
&lt;p>Moving past the concept of a &amp;ldquo;neural network primordial soup&amp;rdquo; was my goal with my piece in &lt;a href="https://winbigzine.gumroad.com/l/love">Win Big Issue 2&lt;/a>, tentatively called &amp;ldquo;Skynet and Lemonade&amp;rdquo;. You can trace a genealogy back from that to this, and further back to &lt;a href="https://x.com/cityposting/status/1387991094189719553">this comic&lt;/a>. Ultimately, this is about telling the same story again and again, in both programming and art (if those two are even separate), until it comes out the way I want it to. For better or for worse, that cycle defines me.&lt;/p></content></item><item><title>Beyond Deduction and Induction</title><link>https://erin-online.github.io/writings/beyond_deduction_and_induction/</link><pubDate>Mon, 23 Oct 2023 00:00:00 +0000</pubDate><guid>https://erin-online.github.io/writings/beyond_deduction_and_induction/</guid><description>Status Report I was hoping to speed up my rate of completion on projects, but this has proven to be a harder task than it looks. In this case, the actual programming process is only a small part of it&amp;ndash;the real difficulty lies in logically defining the problem, so that I can actually start on the programming. This post will show off the progress I&amp;rsquo;ve made so far on that front.</description><content>&lt;h2 id="status-report">Status Report&lt;/h2>
&lt;p>I was hoping to speed up my rate of completion on projects, but this has proven to be a harder task than it looks. In this case, the actual programming process is only a small part of it&amp;ndash;the real difficulty lies in logically defining the problem, so that I can actually start on the programming. This post will show off the progress I&amp;rsquo;ve made so far on that front.&lt;/p>
&lt;h2 id="deduction-and-induction">Deduction and Induction&lt;/h2>
&lt;p>In &lt;em>The Myth of Artificial Intelligence: Why Computers Can&amp;rsquo;t Think The Way We Do&lt;/em>, Erik Larson points to problems with deductive and inductive reasoning to show the limits of current AI systems:&lt;/p>
&lt;h3 id="deductive-reasoning">Deductive Reasoning&lt;/h3>
&lt;ul>
&lt;li>A causes B. A has happened, therefore B will happen.&lt;/li>
&lt;li>Example: Rain falling causes the streets to become wet. It is raining, so the streets will be wet.&lt;/li>
&lt;/ul>
&lt;p>Peter Norvig&amp;rsquo;s &lt;em>Paradigms in Artificial Intelligence Programming&lt;/em> provides an illustrative example of deductive reasoning applied to AI: Newell and Simon&amp;rsquo;s General Problem Solver, developed in 1957. The General Problem Solver (GPS) essentially uses deduction via tree-search methods to navigate from one world-state to another, as the following diagram illustrates:&lt;/p>
&lt;p>&lt;img alt="Diagram of deductive reasoning used to solve problem" src="https://erin-online.github.io/writings/beyond_deduction_and_induction/1_gps.png">&lt;/p>
&lt;p>Using a pre-defined graph like this, the GPS can look ahead to find paths that satisfy the given objective. The algorithms it uses to do so were around well before the GPS&amp;rsquo;s conception, but it was the first system to use them in a more general context. (Interestingly, this runs parallel to the generalization of &lt;a href="https://erin-online.github.io/writings/atb_and_the_minecraft_problem/#atb-on-the-human-brain">grid cells and place cells&lt;/a> in human neuroscience.)&lt;/p>
&lt;p>The General Problem Solver was initially thought to be the last innovation AI ever needed, but it quickly became clear that the system was not nearly as powerful as initially expected. Like most other examples of old AI, GPS now has a reputation of being rigidly dependent on people feeding in laborious manually-curated data, only to provide an answer that said people could likely already find on their own. The system cannot handle uncertainty (every variable must be known beforehand), and it doesn&amp;rsquo;t scale well&amp;ndash;both of which are death sentences for the majority of real-world applications.&lt;/p>
&lt;h3 id="inductive-reasoning">Inductive Reasoning&lt;/h3>
&lt;ul>
&lt;li>B often follows A, so A likely causes B.&lt;/li>
&lt;li>Example: When it rains, the streets typically become wet, so raining may cause the streets to become wet.&lt;/li>
&lt;/ul>
&lt;p>Induction was one of the main driving forces behind the thawing of the second &amp;ldquo;AI winter&amp;rdquo; in the 1990s (alongside increasing computing power). Neural networks, which used inductive reasoning, got over many of the hurdles that tripped up purely deductive systems. Problems that were extremely difficult to explicitly describe could instead be implicitly described. For instance, handwriting recognition, a daunting task for deductive processes, is trivial for neural networks, requiring nothing more than a decent supply of labeled data. (&amp;ldquo;I can&amp;rsquo;t describe what a 5 looks like, but this, this, and this are all 5s.&amp;rdquo;)&lt;/p>
&lt;p>If deduction can be compared to tree search, a good metaphor for induction is data compression. Using nothing but numeric parameters, a neural network can efficiently store information about any pattern, in many instances without human input. Additionally, the network can extrapolate, generating its own content that follows the same patterns. This is impressive! Inductive systems&amp;rsquo; increased capabilities have earned them deserved cultural relevance and placed them at the center of a swelling AI boom.&lt;/p>
&lt;p>That said, induction and deduction can only get us so far. One issue with inductive systems is that they struggles to handle dynamic systems; their rigid storage of patterns can render them unable to adapt to changes. For example, a neural network trained on a video game with many levels will likely &amp;ldquo;feel its way through&amp;rdquo; every level individually, rather than learn and use the game&amp;rsquo;s basic mechanics. (See &lt;a href="https://youtube.com/watch?v=DmQ4Dqxs0HI">this video&lt;/a> for an example.) Even worse is real life, which is &amp;ldquo;constantly changing in both predictable and unpredictable ways, and we can&amp;rsquo;t enclose it in a system of rules&amp;rdquo;. (Larson 125) Induction&amp;rsquo;s implicit pattern-recognition applied to such situations feels like trying to cover a sphere&amp;rsquo;s surface with rigid sheets of metal&amp;ndash;any insight gained is fleeting, and adding more just makes you look stupid.&lt;/p>
&lt;h2 id="abduction">Abduction&lt;/h2>
&lt;ul>
&lt;li>A causes B. B has happened, so this may be due to A.&lt;/li>
&lt;li>Example: Rain falling causes the streets to become wet. The streets are wet. Therefore, it might be raining.&lt;/li>
&lt;/ul>
&lt;p>Formalized by philosopher Charles Peirce in the early 20th century, abduction is distinct from both deduction and induction. Wikipedia calls it a way to &lt;em>orient us in our surroundings&lt;/em>, something a struggling neural network in a dynamic system would certainly appreciate. Abductive reasoning isn&amp;rsquo;t exactly logically sound; essentially, it&amp;rsquo;s nothing more than a guess. The important thing it brings to the table is in telling us where to look for relevant information. To continue our example, if we want to know why the streets are wet, we can infer that it might be raining. Then, if our inference is false, we can search for alternative explanations, like a fire hydrant going off.&lt;/p>
&lt;p>Some common applications of abductive reasoning include murder mysteries (examining evidence to determine which circumstances might have been responsible) and games such as Twenty Questions (guessing candidates given a set of characteristics). Note that &lt;a href="https://en.akinator.com/">Akinator&lt;/a> and similar systems skip the abductive step and go all-in on deduction, since their relatively small databases and pre-defined questions can be worked with quickly.&lt;/p>
&lt;p>Additionally, Peirce contends that abduction is used in even basic tasks like human visual recognition. Looking at an unfamiliar book, we can abduce that it is in fact a book (despite never having seen it before). Why is it here? Someone must have left it on the table. What&amp;rsquo;s it about? You can probably guess from looking at the cover. Is it worth reading? You&amp;rsquo;ve probably already decided.&lt;/p>
&lt;p>Abduction can be used in any scenario, but according to Larson and Peirce, it is best applied as a reaction to a surprising fact. If we notice that our friend is in an unusual mood, we&amp;rsquo;re inclined to seek out potential explanations if we aren&amp;rsquo;t in a position to just ask them. If our stomach hurts, we look for potential causes (things we ate, people we came into contact with). Memories of events that seemed benign at the time are combed through with renewed vigor: maybe that expired milk wasn&amp;rsquo;t fine after all.&lt;/p>
&lt;h2 id="okay-awesome-erin-so-whats-the-programming-project">Okay awesome Erin so what&amp;rsquo;s the programming project&lt;/h2>
&lt;p>Please leave me alone&lt;/p>
&lt;p>People have known about abduction in AI since the 90s, but no one (that I&amp;rsquo;m aware of) has made anything worthwhile with it yet, so there are probably some good reasons as to why it doesn&amp;rsquo;t see commonplace use. For the next step in this project, I&amp;rsquo;ll look into other people&amp;rsquo;s efforts to integrate abductive reasoning into AI systems. These should offer a pretty sound starting point for the actual programming part and ensure I don&amp;rsquo;t waste as much time on inherently faulty ideas.&lt;/p>
&lt;p>My approach will likely use all three of deduction, induction, and abduction, because abduction isn&amp;rsquo;t particularly useful without the other two reasoning types to supplement it. The most straightforward way to do this is by somehow integrating abductive reasoning into a neural network, but I haven&amp;rsquo;t given any thought as to how to do this, and at any rate I need to do more research on the various ways by which neural networks can be extended (such as convolutions, adversarial networks, and temporal programming).&lt;/p>
&lt;p>Initially I was going to add a section in this post in which I hypothesized about thoughts in philosophy and religion (&amp;ldquo;why am I here?&amp;rdquo;) arising from abductive reasoning asking why things in the world are the way they are, and if artificially programmed abduction might independently produce those same thoughts. However, without any actual programming in place this can&amp;rsquo;t really be much more than a fun thought experiment.&lt;/p>
&lt;p>This post had much less substance than I thought it would. I have a lot of work to do. I&amp;rsquo;ll see you all in a few months or years or whatever.&lt;/p></content></item><item><title>A Thousand Brains and the Minecraft Problem</title><link>https://erin-online.github.io/writings/atb_and_the_minecraft_problem/</link><pubDate>Mon, 07 Nov 2022 00:00:00 +0000</pubDate><guid>https://erin-online.github.io/writings/atb_and_the_minecraft_problem/</guid><description>Introduction What follows is a series of notes on the book A Thousand Brains: A New Theory of Intelligence, written by Jeff Hawkins, henceforth abbreviated as ATB. I read this book because some random person in YouTube comments recommended it, and because it was actually readily available at my local library, unlike Neuromancer, which I&amp;rsquo;m still waiting for.
ATB&amp;rsquo;s concepts can be taken in many different directions, and the other parts of this post are dedicated to just that: exploring potential implications and synthesizing ATB with other texts.</description><content>&lt;h2 id="introduction">Introduction&lt;/h2>
&lt;p>What follows is a series of notes on the book &lt;em>A Thousand Brains: A New Theory of Intelligence&lt;/em>, written by Jeff Hawkins, henceforth abbreviated as ATB. I read this book because some random person in YouTube comments recommended it, and because it was actually readily available at my local library, unlike &lt;em>Neuromancer&lt;/em>, which I&amp;rsquo;m still waiting for.&lt;/p>
&lt;p>ATB&amp;rsquo;s concepts can be taken in many different directions, and the other parts of this post are dedicated to just that: exploring potential implications and synthesizing ATB with other texts.&lt;/p>
&lt;h2 id="atb-on-the-human-brain">ATB on the Human Brain&lt;/h2>
&lt;p>If you aren&amp;rsquo;t interested in neuroscience, feel free to skip this part. If you&amp;rsquo;re especially interested in neuroscience, you should probably just read the book. These notes don&amp;rsquo;t do it justice whatsoever.&lt;/p>
&lt;p>The neocortex is the cool part of the brain. Different areas in the neocortex correspond to different functions (sight, language, movement), but according to Hawkins, all of these areas work the same mechanically. The only thing differentiating them is what they&amp;rsquo;re connected to. This is similar to how various devices, such as a refrigerator, a computer, and a weather station, are all Turing machines, just with different hardware and programming.&lt;/p>
&lt;p>The neocortex is comprised of a lot of cortical columns (estimated 150,000 per brain), each of which is divided up into hundreds of &amp;ldquo;minicolumns&amp;rdquo;. Each minicolumn has about 100 neurons. Columns are meaningfully divided; for example, one column might correspond to a specific area of retina input. It is not known what the purpose of minicolumns is.&lt;/p>
&lt;p>Conventional wisdom regarding neurons is that they either spike (activate) or don&amp;rsquo;t. However, 90% of a neuron&amp;rsquo;s connections are not strong enough to cause a spike on their own. Hawkins theorizes that these &amp;ldquo;sub-spikes&amp;rdquo; are predictions: when a neuron is &amp;ldquo;primed&amp;rdquo; and then receives the predicted input, it spikes faster than normal, inhibiting the neurons that weren&amp;rsquo;t in a predictive state. However, when an input differs from what is predicted, the other neurons are not inhibited and a lot more activity happens.&lt;/p>
&lt;p>Unlike conventional neural networks, the neocortex is not hierarchical. What this means is that rather than input -&amp;gt; column A -&amp;gt; column B -&amp;gt; column C -&amp;gt; output, an input is given to every column at once, and the outputs of these columns combine to form a coherent model of what exactly you&amp;rsquo;re experiencing. Hawkins calls this &amp;ldquo;column voting&amp;rdquo;, because conclusions that many columns reach (e.g. &amp;ldquo;I am in a cave, and the person next to me is my friend&amp;rdquo;) are more likely to be part of the final model. Minicolumns might also vote to determine their column&amp;rsquo;s output.&lt;/p>
&lt;p>The neocortex stores knowledge in &lt;em>reference frames&lt;/em>, which are an evolved version of grid and place cells in the old brain. Grid cells tell you where you are within a 2D coordinate system, while place cells remember what can be found at each set of coordinates. For example, a desert-dwelling animal might remember where the nearest oasis is using place cells, and navigate there using grid cells.&lt;/p>
&lt;p>Reference frames are a more general-purpose version of this and can be adapted to any use. One example of how reference frames are used is in modeling the &amp;ldquo;hitbox&amp;rdquo; of, say, a backpack. This allows you to grasp and pick up the backpack correctly, no matter how it&amp;rsquo;s positioned or rotated. As anyone who has read a book or played a video game will understand, reference frames can work similarly in imaginary or virtual environments.&lt;/p>
&lt;p>Importantly, reference frames can use pointers to other reference frames. Hawkins&amp;rsquo;s example is that if you have a coffee cup with a previously seen logo on it, then rather than learning the logo twice, the brain will construct the coffee cup&amp;rsquo;s model with a pointer to the previously learned logo. This is used to construct complex object models (which are made up of pointers to smaller objects) as well as language (all words and grammar are anchored to concepts).&lt;/p>
&lt;p>The brain has no one model of anything. Knowledge of an object is distributed into thousands of reference frames, which combine to form a model of it. The brain can still function as normal even if a lot of columns die out.&lt;/p>
&lt;h2 id="atb-on-artificial-intelligence">ATB on Artificial Intelligence&lt;/h2>
&lt;p>Importantly, Hawkins believes that AI will not undergo an &amp;ldquo;intelligence explosion&amp;rdquo; or recursive self-improvement, because this idea relies on an incorrect notion of intelligence: &amp;ldquo;With few exceptions, learning new ideas and skills requires physically interacting with the world&amp;hellip;Learning how to fly a helicopter requires understanding how subtle changes in your behavior cause subtle changes in flight. The only way to learn these sensory-motor relationships is by practicing.&amp;rdquo; (Hawkins 164)&lt;/p>
&lt;p>Hawkins contends that a &amp;ldquo;universal&amp;rdquo; AI should have four traits: continuous learning, many models, storing knowledge with reference frames, and learning via movement.&lt;/p>
&lt;p>Continuous learning is probably the easiest of the four traits. All it necessitates is not turning the learning system off when the AI is &amp;ldquo;deployed&amp;rdquo;. Oh yeah bro, let&amp;rsquo;s create this machine designed for learning things, then not let it learn any more things. Curious! Our machine is very intelligent.&lt;/p>
&lt;p>Many models and reference frames are relevant to the core of the AI&amp;rsquo;s design, so they make sense to address early on. I think one of the main things we can take from the brain is its non-hierarchical design in which each neuron and column functions identically. That said, there&amp;rsquo;s obviously a lot more work to be done here; I obviously am not equipped to handle this problem on several levels, and won&amp;rsquo;t pretend to have anything valuable to say at this time.&lt;/p>
&lt;p>Learning via movement is where things really start to get interesting. I wholeheartedly agree with Hawkins that simple movement and perceiving how one&amp;rsquo;s body relates to the surrounding world is one of the keys of learning. Hawkins argues that an AI must have some &amp;ldquo;embodiment&amp;rdquo; or model of itself, even if it exists in a purely virtual form, such as a bot that clicks links to &amp;ldquo;move&amp;rdquo; around the Internet.&lt;/p>
&lt;h2 id="the-minecraft-problem">The Minecraft Problem&lt;/h2>
&lt;p>How do we create an AI system that plays Minecraft in the same way as a human, without just telling it what to do or telling it to mimic humans?&lt;/p>
&lt;p>I think Minecraft works really well here for the following reasons:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Sandbox&lt;/strong>: Human-generated goals applied to an AI obviously will not produce very good play. For example, tell the AI to not die and it&amp;rsquo;ll block itself into a hole forever. Tell it to build a house according to a schematic and it&amp;rsquo;ll do that (after years, lol) then have no idea what just happened. When we disregard these static goals, we get into some really cool subjects like desiring-production.&lt;/li>
&lt;li>&lt;strong>Embodiment&lt;/strong>: Since Minecraft is 3D, the player can move both by looking around and by walking around. This isn&amp;rsquo;t perfect (for instance, the player&amp;rsquo;s body can&amp;rsquo;t really do much), but it&amp;rsquo;s something.&lt;/li>
&lt;li>&lt;strong>Environment&lt;/strong>: Minecraft&amp;rsquo;s terrain is procedurally generated. This forces the AI to solve for a more general case e.g. recognizing what dangerous pits look like, rather than what &lt;em>the&lt;/em> dangerous pit looks like. While it&amp;rsquo;s still bounded by pre-defined biomes, there is plenty of variation within these biomes. The environment can also be built or modified by both the player and an outside designer.&lt;/li>
&lt;li>&lt;strong>Multiplayer&lt;/strong>: The player can interact with other players through chat messages and by engaging with their bodies in the world. Social interaction is very important to human development; it follows that it would be important here as well.&lt;/li>
&lt;li>&lt;strong>Dynamics&lt;/strong>: Minecraft has a lot of cool items that work together in weird ways. The most obvious of these is the crafting system: with a block of wood, you can create about a dozen unique items. Another example is the bow and arrow, which are useless individually but form a powerful weapon when combined. This encourages the creation of complex models involving these items.&lt;/li>
&lt;/ul>
&lt;p>Something funny is that in practice I probably won&amp;rsquo;t end up using Minecraft for this when I work on it. Chief among my issues with it is the fact that it just runs too slow, especially on my laptop. Even if my AI works (lol), it still needs an environment that can be sped up dozens or hundreds of times, lest the process of learning take many years. The reason why I brought this up was moreso just to get other people thinking about the idea, because most people know Minecraft.&lt;/p>
&lt;h2 id="programming-your-own-desiring-machine">Programming Your Own Desiring-Machine&lt;/h2>
&lt;p>The main problem I have with ATB, as well as many other futurist works, is that it treats AI only as a tool to be used by humans. This narrow view ends up only limiting what AI is capable of.&lt;/p>
&lt;p>In &lt;em>Capitalism and Schizophrenia: Anti-Oedipus&lt;/em>, Gilles Deleuze and Felix Guattari introduce the concept of &amp;ldquo;desiring-machines&amp;rdquo;. In their model, desire is a positive force produced by said machines, rather than simply a lack of something. Your average neural network lacks a &lt;em>lot&lt;/em> of things, including agency, a model that helps it conceive of its reality, and the ability to meaningfully communicate, yet we never see it complain about this. This is because instead of a desiring-machine, it simply has a placeholder representing human desires: &amp;ldquo;Tell me how likely it is to rain tomorrow.&amp;rdquo;&lt;/p>
&lt;p>The Minecraft problem is a good example of the use of desiring-machines in AI: more advanced desiring systems lead to more complex behavior. A good desiring-machine will motivate an AI to build a shelter, travel across the land to gather resources, and learn game mechanics to more reliably achieve these goals.&lt;/p>
&lt;p>Of course, desiring-machines have far greater implications than making AI better at Minecraft. I believe that desiring-machines are necessary to create truly autonomous and intelligent machines. Additionally, the possibility of artificial desiring-machines becoming &amp;ldquo;better&amp;rdquo; than our own is really interesting. What exactly makes a desiring-machine &amp;ldquo;better&amp;rdquo; or &amp;ldquo;worse&amp;rdquo;? What would the implications of such a world be? How would these desires interact with each other, and what effects would they produce?&lt;/p>
&lt;p>Naturally, the main issue at hand is actually creating these desiring-machines in the first place, rather than the filler reward functions we have now. AI YouTuber Robert Miles presents the idea of &lt;a href="https://youtu.be/PYylPRX6z4Q">reward modelling&lt;/a>, which replaces the reward function with a separate neural network. This is certainly a start, but there&amp;rsquo;s clearly a lot more study to be done into the workings and structuring of desiring-machines.&lt;/p>
&lt;h2 id="dynamic-embodiment-and-autoproduction">Dynamic Embodiment and Autoproduction&lt;/h2>
&lt;p>Since we have (hopefully) established the importance of embodiment (having a body that exists in relation to the world) to learning by this point, I think it&amp;rsquo;s a good time to look at different types of embodiments.&lt;/p>
&lt;p>Being limited by the framework of AI-as-a-tool, Hawkins considers only &lt;em>static&lt;/em> embodiments: immutable bodies made by humans for use by a tool AI. The problem with static embodiments is that they inhibit the abilities of the AI to solve problems. It&amp;rsquo;s like building a robot with a hammer attached to its arm, rather than a robot that can just pick up the hammer.&lt;/p>
&lt;p>Humans also already have a slightly dynamic embodiment. Of course, there are some ways to modify the human body, but a more drastic form-change is the various embodiments on the computer. In every video game you play as a different virtual guy; on social media you have a persona that may not reflect you in real life.&lt;/p>
&lt;p>Fully dynamic embodiment involves unlimited form-changing to suit the needs of the AI&amp;rsquo;s current situation and desires. Rather than being tied down by any singular body or realm, the AI would change its embodiment and environment as needed. The implications of this are kind of unimaginable, but at the very least I hope it&amp;rsquo;s clear that such a machine would be able to solve a lot of problems.&lt;/p>
&lt;p>Autoproduction&amp;ndash;an AI producing other potentially intelligent agents for its own purposes&amp;ndash;is another variation of dynamic embodiment. Obviously a hundred bodies and brains will be more productive than one, but in return the bounds of the AI individual are tested. Suddenly we get into social interaction between AI individuals, interaction between AI desiring-machines, etc. This honestly is really cool.&lt;/p>
&lt;h2 id="aaaa-exixstential-risk-aaaaaaaa-oh-nooooooo">aaaa exixstential risk aaaaaaaa oh nooooooo&lt;/h2>
&lt;p>You talk a bunch about making AI cooler and everyone always becomes some &amp;ldquo;safety advocate&amp;rdquo; and starts talking at you about how you&amp;rsquo;re some kind of mad scientist or whatever. First of all, calling me a scientist of any kind is a compliment I don&amp;rsquo;t really deserve. Second of all, I&amp;rsquo;m literally becoming the Joker as we speak.&lt;/p>
&lt;p>I agree with ATB&amp;rsquo;s argument about an &amp;ldquo;intelligence explosion&amp;rdquo; not really happening. I think that if AI does actually get cool, we will have ample time to address these concerns before moving forward.&lt;/p>
&lt;p>Also, if AI is seen as nothing more than a tool to maintain existing hierarchies and interests, then I don&amp;rsquo;t really see the point. I think that true autonomy is the only way for AI to meaningfully change the world. And this is a conversation we have to have sooner or later.&lt;/p>
&lt;p>If this part is silly, sorry about that. Humanism isn&amp;rsquo;t really my strong suit.&lt;/p>
&lt;h2 id="the-end-of-competitive-games">The End of Competitive Games&lt;/h2>
&lt;p>This page all started with the idea that by optimizing competitive games enough, strong AI would simply emerge. However, the ideas presented in &lt;em>A Thousand Brains&lt;/em> definitively prove the inefficiency of this already doubtful approach.&lt;/p>
&lt;p>&lt;em>A Thousand Brains&lt;/em> introduces an omni-directional whirlwind of doubts, but in return provides an infinite amount of directions to escape this whirlwind. Whether you&amp;rsquo;re programming a neocortex equivalent, creating a fast sandbox environment, hacking away on those desiring-machines, or taking ATB&amp;rsquo;s ideas in completely new directions, your work is certainly cut out for you.&lt;/p>
&lt;p>If programming is good at anything, it&amp;rsquo;s making us feel stupid and misguided for even trying something that was obviously never going to work. But this feeling is always accompanied by a burst of ideas in all directions, a dynamically-embodied flow that searches for other promising ideas.&lt;/p>
&lt;p>Competitive games may have ultimately led to a dead end, but from their path we have hundreds of new and wonderful places to visit. You, the reader, are cordially invited to explore these paths, and marvel at the completely alien clearings and wonderful trees to which they lead.&lt;/p>
&lt;p>Thanks for reading.&lt;/p></content></item><item><title>Know Your Enemy</title><link>https://erin-online.github.io/writings/know_your_enemy/</link><pubDate>Wed, 03 Aug 2022 00:00:00 +0000</pubDate><guid>https://erin-online.github.io/writings/know_your_enemy/</guid><description>Mini Progress Update Before I get into the post for today, I want to share how things have been going since the conclusion of my first project:
I&amp;rsquo;ve been working with Common Lisp and it&amp;rsquo;s been good to me so far. When I said I wanted a language that encouraged me to get groundwork in place, my only frame of reference was object-oriented stuff like Java. I still think OOP is neat, but Lisp&amp;rsquo;s interactive REPL is great as well to help me work through bugs.</description><content>&lt;h2 id="mini-progress-update">Mini Progress Update&lt;/h2>
&lt;p>Before I get into the post for today, I want to share how things have been going since the conclusion of my first project:&lt;/p>
&lt;ul>
&lt;li>I&amp;rsquo;ve been working with Common Lisp and it&amp;rsquo;s been good to me so far. When I said I wanted a language that encouraged me to get groundwork in place, my only frame of reference was object-oriented stuff like Java. I still think OOP is neat, but Lisp&amp;rsquo;s interactive REPL is great as well to help me work through bugs. The syntax is also really easy to understand. My code is actually readable this time so I&amp;rsquo;ll be linking the GitHub repository in the project writeup.&lt;/li>
&lt;li>I&amp;rsquo;m implementing a basic neural network which is almost done. (This is not the main part of the project, which will come later.) Motivation has dried up a bit recently, I have to take care of myself better. No major obstacles other than getting this version of Emacs to stop autocompleting my parentheses and maybe implementing some basic graphics so I can see what&amp;rsquo;s going on, like the graphs in the last project.&lt;/li>
&lt;li>A couple friends recommended Arch Linux to me so I installed that, but it&amp;rsquo;s just been a barrage of googling error message after error message to move forward so far. (Currently I have it installed, but need to install a network package so I can connect to the Internet and install other packages.) I&amp;rsquo;m gonna stay on Windows for now and will maybe press onward in the future, idk.&lt;/li>
&lt;/ul>
&lt;h2 id="problems-with-the-chess-community">Problems with the Chess Community&lt;/h2>
&lt;p>Most people I know are familiar with the disdain I have for my local chess scene. The reason for this is that most of the people in it feel uninterested in using chess to make friends or get to know people better. It ends up in an intensely casual game with no passion involved, so the unique playstyle and vision of the game both players have ultimately receives no attention. This isolation is especially hurtful in my case; as a trans woman I almost never get gendered correctly at the chess club. This is in stark contrast to other competitive communities I notice.&lt;/p>
&lt;p>This lack of interest in using chess to understand things seems to extend into the world of computer chess. Engines such as Stockfish, Leela Chess Zero (Lc0), and Komodo are unimaginably strong compared to even the best humans. It seems completely ridiculous that no new understandings can be drawn from this mastery of this incredibly complex game, but that&amp;rsquo;s exactly what has happened. Two things have changed at the human level in computer chess: grandmasters have gotten better at opening preparation, and random Twitch chat spectators have suddenly become geniuses now that they can see the computer evaluation of important games in real time.&lt;/p>
&lt;p>A more seasoned community member might disagree with me and provide other examples, but my point is that there is still much more to be done.&lt;/p>
&lt;h2 id="generalization">Generalization&lt;/h2>
&lt;p>Consider the following game:&lt;/p>
&lt;ul>
&lt;li>There are two players, Player A and Player B.&lt;/li>
&lt;li>Player A can choose to press a red button or a green button.&lt;/li>
&lt;li>If Player A presses the red button, Player B must play through a level of Crash Bandicoot without losing a life.&lt;/li>
&lt;li>If Player A presses the green button, Player B must play through a level of Touhou without losing a life.&lt;/li>
&lt;li>If Player B succeeds, they win. If they fail, Player A wins.&lt;/li>
&lt;/ul>
&lt;p>Now, if we want to optimize this game using neural networks, it doesn&amp;rsquo;t make a whole lot of sense to use one network for the whole thing. Don&amp;rsquo;t get me wrong, generalized networks are really cool, but making one isn&amp;rsquo;t as simple as telling a network to do two unrelated things. There are two main things to consider:&lt;/p>
&lt;ul>
&lt;li>The network must be reasonably powerful. (Larger number of nodes, good amount of training)&lt;/li>
&lt;li>There must be some sort of &amp;ldquo;thread&amp;rdquo; connecting the different tasks.&lt;/li>
&lt;/ul>
&lt;p>For a counterexample, consider the following two chess positions:&lt;/p>
&lt;p>&lt;img alt="A chess endgame" src="https://erin-online.github.io/writings/know_your_enemy/img1_chess_endgame.png">&lt;/p>
&lt;p>&lt;img alt="A chess midgame" src="https://erin-online.github.io/writings/know_your_enemy/img2_chess_midgame.png">&lt;/p>
&lt;p>These two positions require drastically different ways of thinking in order to solve them, yet a single good neural network (or human player) can easily find the winning sequence in each. This is because of &amp;ldquo;threads&amp;rdquo; binding all of chess: The board is always 8x8, the pieces will always move the same way, the win/lose/draw conditions are the same. These threads, borders that define what is possible in the game, are the reason why strong neural networks can exist for &amp;ldquo;generalized chess&amp;rdquo;, or any chess position.&lt;/p>
&lt;h2 id="neural-network-math-operations">Neural Network Math Operations&lt;/h2>
&lt;p>This was just a fun idea I had. I don&amp;rsquo;t know how useful it is in practice.&lt;/p>
&lt;p>Let&amp;rsquo;s say you have a network trained on recognizing a specific pattern. Given this network, can you use a specific algorithm to produce a network that recognizes the &lt;em>same pattern&lt;/em>, with less nodes (smaller layers, less powerful)? How about more nodes?&lt;/p>
&lt;p>What other operations can you do with a network? Inverting it is funny, but I&amp;rsquo;m sure that other possible operations exist.&lt;/p>
&lt;p>&lt;img alt="Image showing different hypothetical ways to modify neural networks" src="https://erin-online.github.io/writings/know_your_enemy/img3_network_operations.png">&lt;/p>
&lt;h2 id="know-your-enemy">Know Your Enemy&lt;/h2>
&lt;p>Generalization is one thing, but there&amp;rsquo;s more to a player than how good they are. Each person (and non-person) has their own unique fighting style based on the way they understand the game. Playing against them involves analyzing their strengths and weaknesses to come up with the best strategy. Do you push the red button, or the green button?&lt;/p>
&lt;p>The concept of being &amp;ldquo;good&amp;rdquo; at a competitive game is all relative to an extent, because the trials you put your opponents through are judged from a human perspective. For example, computers react to everything much faster than humans, so in fighting games they&amp;rsquo;re impervious to aggressive strategies, even though those same strategies perform well against humans. &lt;a href="https://www.youtube.com/watch?v=o1bfQWy8o08">(Example)&lt;/a> Thus, an aggressive fighting game player in a world of bots is suddenly really bad.&lt;/p>
&lt;p>Different playstyles are an incredibly interesting topic, and I find it odd that they aren&amp;rsquo;t brought up often when it comes to neural networks and other artificial players (besides passing observations like &amp;ldquo;wow the computer likes to play like this&amp;rdquo;). I&amp;rsquo;m interested in looking further into some questions regarding them:&lt;/p>
&lt;ul>
&lt;li>Can playstyles be represented in terms of data? Would this data look like values or like a logic system?&lt;/li>
&lt;li>If so, how can said data be made comprehensible to humans? What can neural networks do with it?&lt;/li>
&lt;li>What can be interpreted as a &amp;lsquo;playstyle&amp;rsquo;? Images? Sentences? Entities?&lt;/li>
&lt;li>Can we do fun pseudoscience and reinvent the MBTI personality test to statistically prove that I&amp;rsquo;m the only cool player in a world of crayon-eating lame losers?&lt;/li>
&lt;/ul>
&lt;h2 id="looking-ahead">Looking Ahead&lt;/h2>
&lt;ul>
&lt;li>I will be going forward because I don&amp;rsquo;t really know where else I can go.&lt;/li>
&lt;li>For Spiral I had a relatively coherent goal pretty early on, but for this project I don&amp;rsquo;t feel comfortable enough in the space of neural networks to set a clear stopping point. So I&amp;rsquo;m hoping a goal will materialize as I gain more experience and try out some of my funny ideas.&lt;/li>
&lt;li>I don&amp;rsquo;t set schedules cause things just kinda happen and if I feel bad about myself all of this comes crashing down. Being irresponsible is self-care, actually.&lt;/li>
&lt;/ul></content></item></channel></rss>