<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>im just vibing. im chilling and vibing on the internet</title><link>https://erin-online.github.io/writings/</link><description>Recent content on im just vibing. im chilling and vibing on the internet</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Mon, 23 Oct 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://erin-online.github.io/writings/index.xml" rel="self" type="application/rss+xml"/><item><title>Beyond Deduction and Induction</title><link>https://erin-online.github.io/writings/beyond_deduction_and_induction/</link><pubDate>Mon, 23 Oct 2023 00:00:00 +0000</pubDate><guid>https://erin-online.github.io/writings/beyond_deduction_and_induction/</guid><description>Status Report I was hoping to speed up my rate of completion on projects, but this has proven to be a harder task than it looks. In this case, the actual programming process is only a small part of it&amp;ndash;the real difficulty lies in logically defining the problem, so that I can actually start on the programming. This post will show off the progress I&amp;rsquo;ve made so far on that front.</description><content>&lt;h2 id="status-report">Status Report&lt;/h2>
&lt;p>I was hoping to speed up my rate of completion on projects, but this has proven to be a harder task than it looks. In this case, the actual programming process is only a small part of it&amp;ndash;the real difficulty lies in logically defining the problem, so that I can actually start on the programming. This post will show off the progress I&amp;rsquo;ve made so far on that front.&lt;/p>
&lt;h2 id="deduction-and-induction">Deduction and Induction&lt;/h2>
&lt;p>In &lt;em>The Myth of Artificial Intelligence: Why Computers Can&amp;rsquo;t Think The Way We Do&lt;/em>, Erik Larson points to problems with deductive and inductive reasoning to show the limits of current AI systems:&lt;/p>
&lt;h3 id="deductive-reasoning">Deductive Reasoning&lt;/h3>
&lt;ul>
&lt;li>A causes B. A has happened, therefore B will happen.&lt;/li>
&lt;li>Example: Rain falling causes the streets to become wet. It is raining, so the streets will be wet.&lt;/li>
&lt;/ul>
&lt;p>Peter Norvig&amp;rsquo;s &lt;em>Paradigms in Artificial Intelligence Programming&lt;/em> provides an illustrative example of deductive reasoning applied to AI: Newell and Simon&amp;rsquo;s General Problem Solver, developed in 1957. The General Problem Solver (GPS) essentially uses deduction via tree-search methods to navigate from one world-state to another, as the following diagram illustrates:&lt;/p>
&lt;p>&lt;img src="1_gps.png" alt="Diagram of deductive reasoning used to solve problem">&lt;/p>
&lt;p>Using a pre-defined graph like this, the GPS can look ahead to find paths that satisfy the given objective. The algorithms it uses to do so were around well before the GPS&amp;rsquo;s conception, but it was the first system to use them in a more general context. (Interestingly, this runs parallel to the generalization of &lt;a href="https://erin-online.github.io/writings/atb_and_the_minecraft_problem/#atb_on_the_human_brain">grid cells and place cells&lt;/a> in human neuroscience.)&lt;/p>
&lt;p>The General Problem Solver was initially thought to be the last innovation AI ever needed, but it quickly became clear that the system was not nearly as powerful as initially expected. Like most other examples of old AI, GPS now has a reputation of being rigidly dependent on people feeding in laborious manually-curated data, only to provide an answer that said people could likely already find on their own. The system cannot handle uncertainty (every variable must be known beforehand), and it doesn&amp;rsquo;t scale well&amp;ndash;both of which are death sentences for the majority of real-world applications.&lt;/p>
&lt;h3 id="inductive-reasoning">Inductive Reasoning&lt;/h3>
&lt;ul>
&lt;li>B often follows A, so A likely causes B.&lt;/li>
&lt;li>Example: When it rains, the streets typically become wet, so raining may cause the streets to become wet.&lt;/li>
&lt;/ul>
&lt;p>Induction was one of the main driving forces behind the thawing of the second &amp;ldquo;AI winter&amp;rdquo; in the 1990s (alongside increasing computing power). Neural networks, which used inductive reasoning, got over many of the hurdles that tripped up purely deductive systems. Problems that were extremely difficult to explicitly describe could instead be implicitly described. For instance, handwriting recognition, a daunting task for deductive processes, is trivial for neural networks, requiring nothing more than a decent supply of labeled data. (&amp;ldquo;I can&amp;rsquo;t describe what a 5 looks like, but this, this, and this are all 5s.&amp;rdquo;)&lt;/p>
&lt;p>If deduction can be compared to tree search, a good metaphor for induction is data compression. Using nothing but numeric parameters, a neural network can efficiently store information about any pattern, in many instances without human input. Additionally, the network can extrapolate, generating its own content that follows the same patterns. This is impressive! Inductive systems&amp;rsquo; increased capabilities have earned them deserved cultural relevance and placed them at the center of a swelling AI boom.&lt;/p>
&lt;p>That said, induction and deduction can only get us so far. One issue with inductive systems is that they struggles to handle dynamic systems; their rigid storage of patterns can render them unable to adapt to changes. For example, a neural network trained on a video game with many levels will likely &amp;ldquo;feel its way through&amp;rdquo; every level individually, rather than learn and use the game&amp;rsquo;s basic mechanics. (See &lt;a href="https://youtube.com/watch?v=DmQ4Dqxs0HI">this video&lt;/a> for an example.) Even worse is real life, which is &amp;ldquo;constantly changing in both predictable and unpredictable ways, and we can&amp;rsquo;t enclose it in a system of rules&amp;rdquo;. (Larson 125) Induction&amp;rsquo;s implicit pattern-recognition applied to such situations feels like trying to cover a sphere&amp;rsquo;s surface with rigid sheets of metal&amp;ndash;any insight gained is fleeting, and adding more just makes you look stupid.&lt;/p>
&lt;h2 id="abduction">Abduction&lt;/h2>
&lt;ul>
&lt;li>A causes B. B has happened, so this may be due to A.&lt;/li>
&lt;li>Example: Rain falling causes the streets to become wet. The streets are wet. Therefore, it might be raining.&lt;/li>
&lt;/ul>
&lt;p>Formalized by philosopher Charles Peirce in the early 20th century, abduction is distinct from both deduction and induction. Wikipedia calls it a way to &lt;em>orient us in our surroundings&lt;/em>, something a struggling neural network in a dynamic system would certainly appreciate. Abductive reasoning isn&amp;rsquo;t exactly logically sound; essentially, it&amp;rsquo;s nothing more than a guess. The important thing it brings to the table is in telling us where to look for relevant information. To continue our example, if we want to know why the streets are wet, we can infer that it might be raining. Then, if our inference is false, we can search for alternative explanations, like a fire hydrant going off.&lt;/p>
&lt;p>Some common applications of abductive reasoning include murder mysteries (examining evidence to determine which circumstances might have been responsible) and games such as Twenty Questions (guessing candidates given a set of characteristics). Note that &lt;a href="https://en.akinator.com/">Akinator&lt;/a> and similar systems skip the abductive step and go all-in on deduction, since their relatively small databases and pre-defined questions can be worked with quickly.&lt;/p>
&lt;p>Additionally, Peirce contends that abduction is used in even basic tasks like human visual recognition. Looking at an unfamiliar book, we can abduce that it is in fact a book (despite never having seen it before). Why is it here? Someone must have left it on the table. What&amp;rsquo;s it about? You can probably guess from looking at the cover. Is it worth reading? You&amp;rsquo;ve probably already decided.&lt;/p>
&lt;p>Abduction can be used in any scenario, but according to Larson and Peirce, it is best applied as a reaction to a surprising fact. If we notice that our friend is in an unusual mood, we&amp;rsquo;re inclined to seek out potential explanations if we aren&amp;rsquo;t in a position to just ask them. If our stomach hurts, we look for potential causes (things we ate, people we came into contact with). Memories of events that seemed benign at the time are combed through with renewed vigor: maybe that expired milk wasn&amp;rsquo;t fine after all.&lt;/p>
&lt;h2 id="okay-awesome-erin-so-whats-the-programming-project">Okay awesome Erin so what&amp;rsquo;s the programming project&lt;/h2>
&lt;p>Please leave me alone&lt;/p>
&lt;p>People have known about abduction in AI since the 90s, but no one (that I&amp;rsquo;m aware of) has made anything worthwhile with it yet, so there are probably some good reasons as to why it doesn&amp;rsquo;t see commonplace use. For the next step in this project, I&amp;rsquo;ll look into other people&amp;rsquo;s efforts to integrate abductive reasoning into AI systems. These should offer a pretty sound starting point for the actual programming part and ensure I don&amp;rsquo;t waste as much time on inherently faulty ideas.&lt;/p>
&lt;p>My approach will likely use all three of deduction, induction, and abduction, because abduction isn&amp;rsquo;t particularly useful without the other two reasoning types to supplement it. The most straightforward way to do this is by somehow integrating abductive reasoning into a neural network, but I haven&amp;rsquo;t given any thought as to how to do this, and at any rate I need to do more research on the various ways by which neural networks can be extended (such as convolutions, adversarial networks, and temporal programming).&lt;/p>
&lt;p>Initially I was going to add a section in this post in which I hypothesized about thoughts in philosophy and religion (&amp;ldquo;why am I here?&amp;rdquo;) arising from abductive reasoning asking why things in the world are the way they are, and if artificially programmed abduction might independently produce those same thoughts. However, without any actual programming in place this can&amp;rsquo;t really be much more than a fun thought experiment.&lt;/p>
&lt;p>This post had much less substance than I thought it would. I have a lot of work to do. I&amp;rsquo;ll see you all in a few months or years or whatever.&lt;/p></content></item><item><title>A Thousand Brains and the Minecraft Problem</title><link>https://erin-online.github.io/writings/atb_and_the_minecraft_problem/</link><pubDate>Mon, 07 Nov 2022 00:00:00 +0000</pubDate><guid>https://erin-online.github.io/writings/atb_and_the_minecraft_problem/</guid><description>Introduction What follows is a series of notes on the book A Thousand Brains: A New Theory of Intelligence, written by Jeff Hawkins, henceforth abbreviated as ATB. I read this book because some random person in YouTube comments recommended it, and because it was actually readily available at my local library, unlike Neuromancer, which I&amp;rsquo;m still waiting for.
ATB&amp;rsquo;s concepts can be taken in many different directions, and the other parts of this post are dedicated to just that: exploring potential implications and synthesizing ATB with other texts.</description><content>&lt;h2 id="introduction">Introduction&lt;/h2>
&lt;p>What follows is a series of notes on the book &lt;em>A Thousand Brains: A New Theory of Intelligence&lt;/em>, written by Jeff Hawkins, henceforth abbreviated as ATB. I read this book because some random person in YouTube comments recommended it, and because it was actually readily available at my local library, unlike &lt;em>Neuromancer&lt;/em>, which I&amp;rsquo;m still waiting for.&lt;/p>
&lt;p>ATB&amp;rsquo;s concepts can be taken in many different directions, and the other parts of this post are dedicated to just that: exploring potential implications and synthesizing ATB with other texts.&lt;/p>
&lt;h2 id="atb-on-the-human-brain">ATB on the Human Brain&lt;/h2>
&lt;p>If you aren&amp;rsquo;t interested in neuroscience, feel free to skip this part. If you&amp;rsquo;re especially interested in neuroscience, you should probably just read the book. These notes don&amp;rsquo;t do it justice whatsoever.&lt;/p>
&lt;p>The neocortex is the cool part of the brain. Different areas in the neocortex correspond to different functions (sight, language, movement), but according to Hawkins, all of these areas work the same mechanically. The only thing differentiating them is what they&amp;rsquo;re connected to. This is similar to how various devices, such as a refrigerator, a computer, and a weather station, are all Turing machines, just with different hardware and programming.&lt;/p>
&lt;p>The neocortex is comprised of a lot of cortical columns (estimated 150,000 per brain), each of which is divided up into hundreds of &amp;ldquo;minicolumns&amp;rdquo;. Each minicolumn has about 100 neurons. Columns are meaningfully divided; for example, one column might correspond to a specific area of retina input. It is not known what the purpose of minicolumns is.&lt;/p>
&lt;p>Conventional wisdom regarding neurons is that they either spike (activate) or don&amp;rsquo;t. However, 90% of a neuron&amp;rsquo;s connections are not strong enough to cause a spike on their own. Hawkins theorizes that these &amp;ldquo;sub-spikes&amp;rdquo; are predictions: when a neuron is &amp;ldquo;primed&amp;rdquo; and then receives the predicted input, it spikes faster than normal, inhibiting the neurons that weren&amp;rsquo;t in a predictive state. However, when an input differs from what is predicted, the other neurons are not inhibited and a lot more activity happens.&lt;/p>
&lt;p>Unlike conventional neural networks, the neocortex is not hierarchical. What this means is that rather than input -&amp;gt; column A -&amp;gt; column B -&amp;gt; column C -&amp;gt; output, an input is given to every column at once, and the outputs of these columns combine to form a coherent model of what exactly you&amp;rsquo;re experiencing. Hawkins calls this &amp;ldquo;column voting&amp;rdquo;, because conclusions that many columns reach (e.g. &amp;ldquo;I am in a cave, and the person next to me is my friend&amp;rdquo;) are more likely to be part of the final model. Minicolumns might also vote to determine their column&amp;rsquo;s output.&lt;/p>
&lt;p>The neocortex stores knowledge in &lt;em>reference frames&lt;/em>, which are an evolved version of grid and place cells in the old brain. Grid cells tell you where you are within a 2D coordinate system, while place cells remember what can be found at each set of coordinates. For example, a desert-dwelling animal might remember where the nearest oasis is using place cells, and navigate there using grid cells.&lt;/p>
&lt;p>Reference frames are a more general-purpose version of this and can be adapted to any use. One example of how reference frames are used is in modeling the &amp;ldquo;hitbox&amp;rdquo; of, say, a backpack. This allows you to grasp and pick up the backpack correctly, no matter how it&amp;rsquo;s positioned or rotated. As anyone who has read a book or played a video game will understand, reference frames can work similarly in imaginary or virtual environments.&lt;/p>
&lt;p>Importantly, reference frames can use pointers to other reference frames. Hawkins&amp;rsquo;s example is that if you have a coffee cup with a previously seen logo on it, then rather than learning the logo twice, the brain will construct the coffee cup&amp;rsquo;s model with a pointer to the previously learned logo. This is used to construct complex object models (which are made up of pointers to smaller objects) as well as language (all words and grammar are anchored to concepts).&lt;/p>
&lt;p>The brain has no one model of anything. Knowledge of an object is distributed into thousands of reference frames, which combine to form a model of it. The brain can still function as normal even if a lot of columns die out.&lt;/p>
&lt;h2 id="atb-on-artificial-intelligence">ATB on Artificial Intelligence&lt;/h2>
&lt;p>Importantly, Hawkins believes that AI will not undergo an &amp;ldquo;intelligence explosion&amp;rdquo; or recursive self-improvement, because this idea relies on an incorrect notion of intelligence: &amp;ldquo;With few exceptions, learning new ideas and skills requires physically interacting with the world&amp;hellip;Learning how to fly a helicopter requires understanding how subtle changes in your behavior cause subtle changes in flight. The only way to learn these sensory-motor relationships is by practicing.&amp;rdquo; (Hawkins 164)&lt;/p>
&lt;p>Hawkins contends that a &amp;ldquo;universal&amp;rdquo; AI should have four traits: continuous learning, many models, storing knowledge with reference frames, and learning via movement.&lt;/p>
&lt;p>Continuous learning is probably the easiest of the four traits. All it necessitates is not turning the learning system off when the AI is &amp;ldquo;deployed&amp;rdquo;. Oh yeah bro, let&amp;rsquo;s create this machine designed for learning things, then not let it learn any more things. Curious! Our machine is very intelligent.&lt;/p>
&lt;p>Many models and reference frames are relevant to the core of the AI&amp;rsquo;s design, so they make sense to address early on. I think one of the main things we can take from the brain is its non-hierarchical design in which each neuron and column functions identically. That said, there&amp;rsquo;s obviously a lot more work to be done here; I obviously am not equipped to handle this problem on several levels, and won&amp;rsquo;t pretend to have anything valuable to say at this time.&lt;/p>
&lt;p>Learning via movement is where things really start to get interesting. I wholeheartedly agree with Hawkins that simple movement and perceiving how one&amp;rsquo;s body relates to the surrounding world is one of the keys of learning. Hawkins argues that an AI must have some &amp;ldquo;embodiment&amp;rdquo; or model of itself, even if it exists in a purely virtual form, such as a bot that clicks links to &amp;ldquo;move&amp;rdquo; around the Internet.&lt;/p>
&lt;h2 id="the-minecraft-problem">The Minecraft Problem&lt;/h2>
&lt;p>How do we create an AI system that plays Minecraft in the same way as a human, without just telling it what to do or telling it to mimic humans?&lt;/p>
&lt;p>I think Minecraft works really well here for the following reasons:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Sandbox&lt;/strong>: Human-generated goals applied to an AI obviously will not produce very good play. For example, tell the AI to not die and it&amp;rsquo;ll block itself into a hole forever. Tell it to build a house according to a schematic and it&amp;rsquo;ll do that (after years, lol) then have no idea what just happened. When we disregard these static goals, we get into some really cool subjects like desiring-production.&lt;/li>
&lt;li>&lt;strong>Embodiment&lt;/strong>: Since Minecraft is 3D, the player can move both by looking around and by walking around. This isn&amp;rsquo;t perfect (for instance, the player&amp;rsquo;s body can&amp;rsquo;t really do much), but it&amp;rsquo;s something.&lt;/li>
&lt;li>&lt;strong>Environment&lt;/strong>: Minecraft&amp;rsquo;s terrain is procedurally generated. This forces the AI to solve for a more general case e.g. recognizing what dangerous pits look like, rather than what &lt;em>the&lt;/em> dangerous pit looks like. While it&amp;rsquo;s still bounded by pre-defined biomes, there is plenty of variation within these biomes. The environment can also be built or modified by both the player and an outside designer.&lt;/li>
&lt;li>&lt;strong>Multiplayer&lt;/strong>: The player can interact with other players through chat messages and by engaging with their bodies in the world. Social interaction is very important to human development; it follows that it would be important here as well.&lt;/li>
&lt;li>&lt;strong>Dynamics&lt;/strong>: Minecraft has a lot of cool items that work together in weird ways. The most obvious of these is the crafting system: with a block of wood, you can create about a dozen unique items. Another example is the bow and arrow, which are useless individually but form a powerful weapon when combined. This encourages the creation of complex models involving these items.&lt;/li>
&lt;/ul>
&lt;p>Something funny is that in practice I probably won&amp;rsquo;t end up using Minecraft for this when I work on it. Chief among my issues with it is the fact that it just runs too slow, especially on my laptop. Even if my AI works (lol), it still needs an environment that can be sped up dozens or hundreds of times, lest the process of learning take many years. The reason why I brought this up was moreso just to get other people thinking about the idea, because most people know Minecraft.&lt;/p>
&lt;h2 id="programming-your-own-desiring-machine">Programming Your Own Desiring-Machine&lt;/h2>
&lt;p>The main problem I have with ATB, as well as many other futurist works, is that it treats AI only as a tool to be used by humans. This narrow view ends up only limiting what AI is capable of.&lt;/p>
&lt;p>In &lt;em>Capitalism and Schizophrenia: Anti-Oedipus&lt;/em>, Gilles Deleuze and Felix Guattari introduce the concept of &amp;ldquo;desiring-machines&amp;rdquo;. In their model, desire is a positive force produced by said machines, rather than simply a lack of something. Your average neural network lacks a &lt;em>lot&lt;/em> of things, including agency, a model that helps it conceive of its reality, and the ability to meaningfully communicate, yet we never see it complain about this. This is because instead of a desiring-machine, it simply has a placeholder representing human desires: &amp;ldquo;Tell me how likely it is to rain tomorrow.&amp;rdquo;&lt;/p>
&lt;p>The Minecraft problem is a good example of the use of desiring-machines in AI: more advanced desiring systems lead to more complex behavior. A good desiring-machine will motivate an AI to build a shelter, travel across the land to gather resources, and learn game mechanics to more reliably achieve these goals.&lt;/p>
&lt;p>Of course, desiring-machines have far greater implications than making AI better at Minecraft. I believe that desiring-machines are necessary to create truly autonomous and intelligent machines. Additionally, the possibility of artificial desiring-machines becoming &amp;ldquo;better&amp;rdquo; than our own is really interesting. What exactly makes a desiring-machine &amp;ldquo;better&amp;rdquo; or &amp;ldquo;worse&amp;rdquo;? What would the implications of such a world be? How would these desires interact with each other, and what effects would they produce?&lt;/p>
&lt;p>Naturally, the main issue at hand is actually creating these desiring-machines in the first place, rather than the filler reward functions we have now. AI YouTuber Robert Miles presents the idea of &lt;a href="https://youtu.be/PYylPRX6z4Q">reward modelling&lt;/a>, which replaces the reward function with a separate neural network. This is certainly a start, but there&amp;rsquo;s clearly a lot more study to be done into the workings and structuring of desiring-machines.&lt;/p>
&lt;h2 id="dynamic-embodiment-and-autoproduction">Dynamic Embodiment and Autoproduction&lt;/h2>
&lt;p>Since we have (hopefully) established the importance of embodiment (having a body that exists in relation to the world) to learning by this point, I think it&amp;rsquo;s a good time to look at different types of embodiments.&lt;/p>
&lt;p>Being limited by the framework of AI-as-a-tool, Hawkins considers only &lt;em>static&lt;/em> embodiments: immutable bodies made by humans for use by a tool AI. The problem with static embodiments is that they inhibit the abilities of the AI to solve problems. It&amp;rsquo;s like building a robot with a hammer attached to its arm, rather than a robot that can just pick up the hammer.&lt;/p>
&lt;p>Humans also already have a slightly dynamic embodiment. Of course, there are some ways to modify the human body, but a more drastic form-change is the various embodiments on the computer. In every video game you play as a different virtual guy; on social media you have a persona that may not reflect you in real life.&lt;/p>
&lt;p>Fully dynamic embodiment involves unlimited form-changing to suit the needs of the AI&amp;rsquo;s current situation and desires. Rather than being tied down by any singular body or realm, the AI would change its embodiment and environment as needed. The implications of this are kind of unimaginable, but at the very least I hope it&amp;rsquo;s clear that such a machine would be able to solve a lot of problems.&lt;/p>
&lt;p>Autoproduction&amp;ndash;an AI producing itself or simplified versions&amp;ndash;is another variation of dynamic embodiment. Obviously a hundred bodies and brains will be more productive than one, but in return the bounds of the AI individual are tested. Suddenly we get into social interaction between AI individuals, interaction between AI desiring-machines, etc. This honestly is really cool.&lt;/p>
&lt;h2 id="aaaa-exixstential-risk-aaaaaaaa-oh-nooooooo">aaaa exixstential risk aaaaaaaa oh nooooooo&lt;/h2>
&lt;p>You talk a bunch about making AI cooler and everyone always becomes some &amp;ldquo;safety advocate&amp;rdquo; and starts talking at you about how you&amp;rsquo;re some kind of mad scientist or whatever. First of all, calling me a scientist of any kind is a compliment I don&amp;rsquo;t really deserve. Second of all, I&amp;rsquo;m literally becoming the Joker as we speak.&lt;/p>
&lt;p>I agree with ATB&amp;rsquo;s argument about an &amp;ldquo;intelligence explosion&amp;rdquo; not really happening. I think that if AI does actually get cool, we will have ample time to address these concerns before moving forward.&lt;/p>
&lt;p>Also, if AI is seen as nothing more than a tool to maintain existing hierarchies and interests, then I don&amp;rsquo;t really see the point. I think that true autonomy is the only way for AI to meaningfully change the world. And this is a conversation we have to have sooner or later.&lt;/p>
&lt;p>If this part is silly, sorry about that. Humanism isn&amp;rsquo;t really my strong suit.&lt;/p>
&lt;h2 id="the-end-of-competitive-games">The End of Competitive Games&lt;/h2>
&lt;p>This page all started with the idea that by optimizing competitive games enough, strong AI would simply emerge. However, the ideas presented in &lt;em>A Thousand Brains&lt;/em> definitively prove the inefficiency of this already doubtful approach.&lt;/p>
&lt;p>&lt;em>A Thousand Brains&lt;/em> introduces an omni-directional whirlwind of doubts, but in return provides an infinite amount of directions to escape this whirlwind. Whether you&amp;rsquo;re programming a neocortex equivalent, creating a fast sandbox environment, hacking away on those desiring-machines, or taking ATB&amp;rsquo;s ideas in completely new directions, your work is certainly cut out for you.&lt;/p>
&lt;p>If programming is good at anything, it&amp;rsquo;s making us feel stupid and misguided for even trying something that was obviously never going to work. But this feeling is always accompanied by a burst of ideas in all directions, a dynamically-embodied flow that searches for other promising ideas.&lt;/p>
&lt;p>Competitive games may have ultimately led to a dead end, but from their path we have hundreds of new and wonderful places to visit. You, the reader, are cordially invited to explore these paths, and marvel at the completely alien clearings and wonderful trees to which they lead.&lt;/p>
&lt;p>Thanks for reading.&lt;/p></content></item><item><title>Know Your Enemy</title><link>https://erin-online.github.io/writings/know_your_enemy/</link><pubDate>Wed, 03 Aug 2022 00:00:00 +0000</pubDate><guid>https://erin-online.github.io/writings/know_your_enemy/</guid><description>Mini Progress Update Before I get into the post for today, I want to share how things have been going since the conclusion of my first project:
I&amp;rsquo;ve been working with Common Lisp and it&amp;rsquo;s been good to me so far. When I said I wanted a language that encouraged me to get groundwork in place, my only frame of reference was object-oriented stuff like Java. I still think OOP is neat, but Lisp&amp;rsquo;s interactive REPL is great as well to help me work through bugs.</description><content>&lt;h2 id="mini-progress-update">Mini Progress Update&lt;/h2>
&lt;p>Before I get into the post for today, I want to share how things have been going since the conclusion of my first project:&lt;/p>
&lt;ul>
&lt;li>I&amp;rsquo;ve been working with Common Lisp and it&amp;rsquo;s been good to me so far. When I said I wanted a language that encouraged me to get groundwork in place, my only frame of reference was object-oriented stuff like Java. I still think OOP is neat, but Lisp&amp;rsquo;s interactive REPL is great as well to help me work through bugs. The syntax is also really easy to understand. My code is actually readable this time so I&amp;rsquo;ll be linking the GitHub repository in the project writeup.&lt;/li>
&lt;li>I&amp;rsquo;m implementing a basic neural network which is almost done. (This is not the main part of the project, which will come later.) Motivation has dried up a bit recently, I have to take care of myself better. No major obstacles other than getting this version of Emacs to stop autocompleting my parentheses and maybe implementing some basic graphics so I can see what&amp;rsquo;s going on, like the graphs in the last project.&lt;/li>
&lt;li>A couple friends recommended Arch Linux to me so I installed that, but it&amp;rsquo;s just been a barrage of googling error message after error message to move forward so far. (Currently I have it installed, but need to install a network package so I can connect to the Internet and install other packages.) I&amp;rsquo;m gonna stay on Windows for now and will maybe press onward in the future, idk.&lt;/li>
&lt;/ul>
&lt;h2 id="problems-with-the-chess-community">Problems with the Chess Community&lt;/h2>
&lt;p>Most people I know are familiar with the disdain I have for my local chess scene. The reason for this is that most of the people in it feel uninterested in using chess to make friends or get to know people better. It ends up in an intensely casual game with no passion involved, so the unique playstyle and vision of the game both players have ultimately receives no attention. This isolation is especially hurtful in my case; as a trans woman I almost never get gendered correctly at the chess club. This is in stark contrast to other competitive communities I notice.&lt;/p>
&lt;p>This lack of interest in using chess to understand things seems to extend into the world of computer chess. Engines such as Stockfish, Leela Chess Zero (Lc0), and Komodo are unimaginably strong compared to even the best humans. It seems completely ridiculous that no new understandings can be drawn from this mastery of this incredibly complex game, but that&amp;rsquo;s exactly what has happened. Two things have changed at the human level in computer chess: grandmasters have gotten better at opening preparation, and random Twitch chat spectators have suddenly become geniuses now that they can see the computer evaluation of important games in real time.&lt;/p>
&lt;p>A more seasoned community member might disagree with me and provide other examples, but my point is that there is still much more to be done.&lt;/p>
&lt;h2 id="generalization">Generalization&lt;/h2>
&lt;p>Consider the following game:&lt;/p>
&lt;ul>
&lt;li>There are two players, Player A and Player B.&lt;/li>
&lt;li>Player A can choose to press a red button or a green button.&lt;/li>
&lt;li>If Player A presses the red button, Player B must play through a level of Crash Bandicoot without losing a life.&lt;/li>
&lt;li>If Player A presses the green button, Player B must play through a level of Touhou without losing a life.&lt;/li>
&lt;li>If Player B succeeds, they win. If they fail, Player A wins.&lt;/li>
&lt;/ul>
&lt;p>Now, if we want to optimize this game using neural networks, it doesn&amp;rsquo;t make a whole lot of sense to use one network for the whole thing. Don&amp;rsquo;t get me wrong, generalized networks are really cool, but making one isn&amp;rsquo;t as simple as telling a network to do two unrelated things. There are two main things to consider:&lt;/p>
&lt;ul>
&lt;li>The network must be reasonably powerful. (Larger number of nodes, good amount of training)&lt;/li>
&lt;li>There must be some sort of &amp;ldquo;thread&amp;rdquo; connecting the different tasks.&lt;/li>
&lt;/ul>
&lt;p>For a counterexample, consider the following two chess positions:&lt;/p>
&lt;p>&lt;img src="img1_chess_endgame.png" alt="A chess endgame">&lt;/p>
&lt;p>&lt;img src="img2_chess_midgame.png" alt="A chess midgame">&lt;/p>
&lt;p>These two positions require drastically different ways of thinking in order to solve them, yet a single good neural network (or human player) can easily find the winning sequence in each. This is because of &amp;ldquo;threads&amp;rdquo; binding all of chess: The board is always 8x8, the pieces will always move the same way, the win/lose/draw conditions are the same. These threads, borders that define what is possible in the game, are the reason why strong neural networks can exist for &amp;ldquo;generalized chess&amp;rdquo;, or any chess position.&lt;/p>
&lt;h2 id="neural-network-math-operations">Neural Network Math Operations&lt;/h2>
&lt;p>This was just a fun idea I had. I don&amp;rsquo;t know how useful it is in practice.&lt;/p>
&lt;p>Let&amp;rsquo;s say you have a network trained on recognizing a specific pattern. Given this network, can you use a specific algorithm to produce a network that recognizes the &lt;em>same pattern&lt;/em>, with less nodes (smaller layers, less powerful)? How about more nodes?&lt;/p>
&lt;p>What other operations can you do with a network? Inverting it is funny, but I&amp;rsquo;m sure that other possible operations exist.&lt;/p>
&lt;p>&lt;img src="img3_network_operations.png" alt="Image showing different hypothetical ways to modify neural networks">&lt;/p>
&lt;h2 id="know-your-enemy">Know Your Enemy&lt;/h2>
&lt;p>Generalization is one thing, but there&amp;rsquo;s more to a player than how good they are. Each person (and non-person) has their own unique fighting style based on the way they understand the game. Playing against them involves analyzing their strengths and weaknesses to come up with the best strategy. Do you push the red button, or the green button?&lt;/p>
&lt;p>The concept of being &amp;ldquo;good&amp;rdquo; at a competitive game is all relative to an extent, because the trials you put your opponents through are judged from a human perspective. For example, computers react to everything much faster than humans, so in fighting games they&amp;rsquo;re impervious to aggressive strategies, even though those same strategies perform well against humans. &lt;a href="https://www.youtube.com/watch?v=o1bfQWy8o08">(Example)&lt;/a> Thus, an aggressive fighting game player in a world of bots is suddenly really bad.&lt;/p>
&lt;p>Different playstyles are an incredibly interesting topic, and I find it odd that they aren&amp;rsquo;t brought up often when it comes to neural networks and other artificial players (besides passing observations like &amp;ldquo;wow the computer likes to play like this&amp;rdquo;). I&amp;rsquo;m interested in looking further into some questions regarding them:&lt;/p>
&lt;ul>
&lt;li>Can playstyles be represented in terms of data? Would this data look like values or like a logic system?&lt;/li>
&lt;li>If so, how can said data be made comprehensible to humans? What can neural networks do with it?&lt;/li>
&lt;li>What can be interpreted as a &amp;lsquo;playstyle&amp;rsquo;? Images? Sentences? Entities?&lt;/li>
&lt;li>Can we do fun pseudoscience and reinvent the MBTI personality test to statistically prove that I&amp;rsquo;m the only cool player in a world of crayon-eating lame losers?&lt;/li>
&lt;/ul>
&lt;h2 id="looking-ahead">Looking Ahead&lt;/h2>
&lt;ul>
&lt;li>I will be going forward because I don&amp;rsquo;t really know where else I can go.&lt;/li>
&lt;li>For Spiral I had a relatively coherent goal pretty early on, but for this project I don&amp;rsquo;t feel comfortable enough in the space of neural networks to set a clear stopping point. So I&amp;rsquo;m hoping a goal will materialize as I gain more experience and try out some of my funny ideas.&lt;/li>
&lt;li>I don&amp;rsquo;t set schedules cause things just kinda happen and if I feel bad about myself all of this comes crashing down. Being irresponsible is self-care, actually.&lt;/li>
&lt;/ul></content></item></channel></rss>