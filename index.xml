<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>im just vibing. im chilling and vibing on the internet</title><link>https://erin-online.github.io/</link><description>Recent content on im just vibing. im chilling and vibing on the internet</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Mon, 23 Oct 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://erin-online.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>Beyond Deduction and Induction</title><link>https://erin-online.github.io/writings/beyond_deduction_and_induction/</link><pubDate>Mon, 23 Oct 2023 00:00:00 +0000</pubDate><guid>https://erin-online.github.io/writings/beyond_deduction_and_induction/</guid><description>Status Report I was hoping to speed up my rate of completion on projects, but this has proven to be a harder task than it looks. In this case, the actual programming process is only a small part of it&amp;ndash;the real difficulty lies in logically defining the problem, so that I can actually start on the programming. This post will show off the progress I&amp;rsquo;ve made so far on that front.</description><content>&lt;h2 id="status-report">Status Report&lt;/h2>
&lt;p>I was hoping to speed up my rate of completion on projects, but this has proven to be a harder task than it looks. In this case, the actual programming process is only a small part of it&amp;ndash;the real difficulty lies in logically defining the problem, so that I can actually start on the programming. This post will show off the progress I&amp;rsquo;ve made so far on that front.&lt;/p>
&lt;h2 id="deduction-and-induction">Deduction and Induction&lt;/h2>
&lt;p>In &lt;em>The Myth of Artificial Intelligence: Why Computers Can&amp;rsquo;t Think The Way We Do&lt;/em>, Erik Larson points to problems with deductive and inductive reasoning to show the limits of current AI systems:&lt;/p>
&lt;h3 id="deductive-reasoning">Deductive Reasoning&lt;/h3>
&lt;ul>
&lt;li>A causes B. A has happened, therefore B will happen.&lt;/li>
&lt;li>Example: Rain falling causes the streets to become wet. It is raining, so the streets will be wet.&lt;/li>
&lt;/ul>
&lt;p>Peter Norvig&amp;rsquo;s &lt;em>Paradigms in Artificial Intelligence Programming&lt;/em> provides an illustrative example of deductive reasoning applied to AI: Newell and Simon&amp;rsquo;s General Problem Solver, developed in 1957. The General Problem Solver (GPS) essentially uses deduction via tree-search methods to navigate from one world-state to another, as the following diagram illustrates:&lt;/p>
&lt;p>&lt;img src="1_gps.png" alt="Diagram of deductive reasoning used to solve problem">&lt;/p>
&lt;p>Using a pre-defined graph like this, the GPS can look ahead to find paths that satisfy the given objective. The algorithms it uses to do so were around well before the GPS&amp;rsquo;s conception, but it was the first system to use them in a more general context. (Interestingly, this runs parallel to the generalization of &lt;a href="https://erin-online.github.io/writings/atb_and_the_minecraft_problem/#atb_on_the_human_brain">grid cells and place cells&lt;/a> in human neuroscience.)&lt;/p>
&lt;p>The General Problem Solver was initially thought to be the last innovation AI ever needed, but it quickly became clear that the system was not nearly as powerful as initially expected. Like most other examples of old AI, GPS now has a reputation of being rigidly dependent on people feeding in laborious manually-curated data, only to provide an answer that said people could likely already find on their own. The system cannot handle uncertainty (every variable must be known beforehand), and it doesn&amp;rsquo;t scale well&amp;ndash;both of which are death sentences for the majority of real-world applications.&lt;/p>
&lt;h3 id="inductive-reasoning">Inductive Reasoning&lt;/h3>
&lt;ul>
&lt;li>B often follows A, so A likely causes B.&lt;/li>
&lt;li>Example: When it rains, the streets typically become wet, so raining may cause the streets to become wet.&lt;/li>
&lt;/ul>
&lt;p>Induction was one of the main driving forces behind the thawing of the second &amp;ldquo;AI winter&amp;rdquo; in the 1990s (alongside increasing computing power). Neural networks, which used inductive reasoning, got over many of the hurdles that tripped up purely deductive systems. Problems that were extremely difficult to explicitly describe could instead be implicitly described. For instance, handwriting recognition, a daunting task for deductive processes, is trivial for neural networks, requiring nothing more than a decent supply of labeled data. (&amp;ldquo;I can&amp;rsquo;t describe what a 5 looks like, but this, this, and this are all 5s.&amp;rdquo;)&lt;/p>
&lt;p>If deduction can be compared to tree search, a good metaphor for induction is data compression. Using nothing but numeric parameters, a neural network can efficiently store information about any pattern, in many instances without human input. Additionally, the network can extrapolate, generating its own content that follows the same patterns. This is impressive! Inductive systems&amp;rsquo; increased capabilities have earned them deserved cultural relevance and placed them at the center of a swelling AI boom.&lt;/p>
&lt;p>That said, induction and deduction can only get us so far. One issue with inductive systems is that they struggles to handle dynamic systems; their rigid storage of patterns can render them unable to adapt to changes. For example, a neural network trained on a video game with many levels will likely &amp;ldquo;feel its way through&amp;rdquo; every level individually, rather than learn and use the game&amp;rsquo;s basic mechanics. (See &lt;a href="https://youtube.com/watch?v=DmQ4Dqxs0HI">this video&lt;/a> for an example.) Even worse is real life, which is &amp;ldquo;constantly changing in both predictable and unpredictable ways, and we can&amp;rsquo;t enclose it in a system of rules&amp;rdquo;. (Larson 125) Induction&amp;rsquo;s implicit pattern-recognition applied to such situations feels like trying to cover a sphere&amp;rsquo;s surface with rigid sheets of metal&amp;ndash;any insight gained is fleeting, and adding more just makes you look stupid.&lt;/p>
&lt;h2 id="abduction">Abduction&lt;/h2>
&lt;ul>
&lt;li>A causes B. B has happened, so this may be due to A.&lt;/li>
&lt;li>Example: Rain falling causes the streets to become wet. The streets are wet. Therefore, it might be raining.&lt;/li>
&lt;/ul>
&lt;p>Formalized by philosopher Charles Peirce in the early 20th century, abduction is distinct from both deduction and induction. Wikipedia calls it a way to &lt;em>orient us in our surroundings&lt;/em>, something a struggling neural network in a dynamic system would certainly appreciate. Abductive reasoning isn&amp;rsquo;t exactly logically sound; essentially, it&amp;rsquo;s nothing more than a guess. The important thing it brings to the table is in telling us where to look for relevant information. To continue our example, if we want to know why the streets are wet, we can infer that it might be raining. Then, if our inference is false, we can search for alternative explanations, like a fire hydrant going off.&lt;/p>
&lt;p>Some common applications of abductive reasoning include murder mysteries (examining evidence to determine which circumstances might have been responsible) and games such as Twenty Questions (guessing candidates given a set of characteristics). Note that &lt;a href="https://en.akinator.com/">Akinator&lt;/a> and similar systems skip the abductive step and go all-in on deduction, since their relatively small databases and pre-defined questions can be worked with quickly.&lt;/p>
&lt;p>Additionally, Peirce contends that abduction is used in even basic tasks like human visual recognition. Looking at an unfamiliar book, we can abduce that it is in fact a book (despite never having seen it before). Why is it here? Someone must have left it on the table. What&amp;rsquo;s it about? You can probably guess from looking at the cover. Is it worth reading? You&amp;rsquo;ve probably already decided.&lt;/p>
&lt;p>Abduction can be used in any scenario, but according to Larson and Peirce, it is best applied as a reaction to a surprising fact. If we notice that our friend is in an unusual mood, we&amp;rsquo;re inclined to seek out potential explanations if we aren&amp;rsquo;t in a position to just ask them. If our stomach hurts, we look for potential causes (things we ate, people we came into contact with). Memories of events that seemed benign at the time are combed through with renewed vigor: maybe that expired milk wasn&amp;rsquo;t fine after all.&lt;/p>
&lt;h2 id="okay-awesome-erin-so-whats-the-programming-project">Okay awesome Erin so what&amp;rsquo;s the programming project&lt;/h2>
&lt;p>Please leave me alone&lt;/p>
&lt;p>People have known about abduction in AI since the 90s, but no one (that I&amp;rsquo;m aware of) has made anything worthwhile with it yet, so there are probably some good reasons as to why it doesn&amp;rsquo;t see commonplace use. For the next step in this project, I&amp;rsquo;ll look into other people&amp;rsquo;s efforts to integrate abductive reasoning into AI systems. These should offer a pretty sound starting point for the actual programming part and ensure I don&amp;rsquo;t waste as much time on inherently faulty ideas.&lt;/p>
&lt;p>My approach will likely use all three of deduction, induction, and abduction, because abduction isn&amp;rsquo;t particularly useful without the other two reasoning types to supplement it. The most straightforward way to do this is by somehow integrating abductive reasoning into a neural network, but I haven&amp;rsquo;t given any thought as to how to do this, and at any rate I need to do more research on the various ways by which neural networks can be extended (such as convolutions, adversarial networks, and temporal programming).&lt;/p>
&lt;p>Initially I was going to add a section in this post in which I hypothesized about thoughts in philosophy and religion (&amp;ldquo;why am I here?&amp;rdquo;) arising from abductive reasoning asking why things in the world are the way they are, and if artificially programmed abduction might independently produce those same thoughts. However, without any actual programming in place this can&amp;rsquo;t really be much more than a fun thought experiment.&lt;/p>
&lt;p>This post had much less substance than I thought it would. I have a lot of work to do. I&amp;rsquo;ll see you all in a few months or years or whatever.&lt;/p></content></item><item><title>Funny Wacky Lines</title><link>https://erin-online.github.io/projects/funny_wacky_lines/</link><pubDate>Tue, 27 Jun 2023 00:00:00 +0000</pubDate><guid>https://erin-online.github.io/projects/funny_wacky_lines/</guid><description>Project Details When I was looking at the math for how neural networks worked, I got a little skeptical about the math used in them. Since the learning process used nothing but basic calculus principles, in theory there was nothing stopping me from using any function I wanted&amp;ndash; and in practice, it could maybe even be more efficient in some situations.
The finished code is essentially a general-purpose framework that I could use to put in any math function and get a neural network that uses it.</description><content>&lt;h2 id="project-details">Project Details&lt;/h2>
&lt;p>When I was looking at the math for how neural networks worked, I got a little skeptical about the math used in them. Since the learning process used nothing but basic calculus principles, in theory there was nothing stopping me from using any function I wanted&amp;ndash; and in practice, it could maybe even be more efficient in some situations.&lt;/p>
&lt;p>The finished code is essentially a general-purpose framework that I could use to put in any math function and get a neural network that uses it. I tested the resulting networks on simple patterns as a proof-of-concept that they can work.&lt;/p>
&lt;p>You can find the repository &lt;a href="https://github.com/erin-online/lisp-neural">here&lt;/a>. This code is definitely better than last time but still isn&amp;rsquo;t very suited for use by other people. If you want me to make it more accessible, just message me on &lt;a href="https://twitter.com/cityposting">Twitter&lt;/a> or on Discord at cityposting.&lt;/p>
&lt;h2 id="what-does-it-mean-for-a-neural-network-to-use-a-math-function">What does it mean for a neural network to use a math function?&lt;/h2>
&lt;p>Basically, neural networks are functions with a lot of variables that try to match a pattern as closely as possible. The specific pattern in question can be anything. How do they do this? Let&amp;rsquo;s look at an example, the ReLU (Rectified Linear Unit) function:&lt;/p>
&lt;p>&lt;img src="img00_relu_function.png" alt="Graph of the ReLU function: y=x if x is greater than 0, and 0 otherwise.">&lt;/p>
&lt;p>So let&amp;rsquo;s say that we have a mysterious function, and we&amp;rsquo;re trying to fit it as best we can. What we can do is first add in two parameters: a simple multiplier (&amp;ldquo;weight&amp;rdquo;) and a simple vertical movement (&amp;ldquo;bias&amp;rdquo;). Then, we can add together several ReLUs, each with their own weight and bias, to produce an arbitrary pattern:&lt;/p>
&lt;p>&lt;img src="img01_weight_and_bias.png" alt="Visualization of weight and bias"> &lt;img src="img09_relus_sum.png" alt="Sum of each of the ReLUs">&lt;/p>
&lt;p>The more ReLUs we add together (&amp;ldquo;nodes&amp;rdquo;), the more complex a pattern we can make. Additionally, we can feed the resulting pattern into another set of ReLUs (&amp;ldquo;layer&amp;rdquo;), producing a multiplicatively higher rate of complexity:&lt;/p>
&lt;p>&lt;img src="img02_layers.png" alt="Visualization of additional layers">&lt;/p>
&lt;p>This project basically involves using functions other than ReLU, and adding new parameters to tweak.&lt;/p>
&lt;h2 id="you-know-who-else-likes-recursion-you-know-who-else-likes-recursion">You know who else likes recursion? You know who else likes recursion?&lt;/h2>
&lt;p>I was looking for a programming language to use for this project because I didn&amp;rsquo;t want to use Python again. I decided to give Common Lisp a try because several people on the fediverse were always talking about it, and it ended up being an incredibly rewarding experience. Truly cannot recommend this language enough.&lt;/p>
&lt;p>The language structure of Common Lisp lends itself particularly well to recursion, which is basically mandatory if you want to program calculus. This is because you can nest functions within each other as many times as you want; for example e^e^e^e^&amp;hellip;^x or sin(sin(sin(&amp;hellip;sin(x)&amp;hellip;))). Recursion basically entails continually processing the same expression until you finally peel away all the layers, and my get-derivative function ended up working like that:&lt;/p>
&lt;p>&lt;img src="img03_getderivative.png" alt="Demonstration of the get-derivative function">&lt;/p>
&lt;p>The get-derivative function was essentially the backbone of this whole project. Other people have made much better versions of this function, but I was still extremely happy with mine, especially because it&amp;rsquo;s something I&amp;rsquo;ve been wanting to write even before this project specifically.&lt;/p>
&lt;p>I won&amp;rsquo;t go into too much detail about how calculus is used in this project; basically, it&amp;rsquo;s used to automatically tweak the function parameters in order to make them more closely match the pattern. If you&amp;rsquo;re interested in learning more, check out the &lt;a href="https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi">3blue1brown neural network playlist&lt;/a>, which is what I learned from.&lt;/p>
&lt;h2 id="dual-boot-gaming-or-pain-and-suffering">Dual Boot Gaming (or: Pain and Suffering)&lt;/h2>
&lt;p>It was really important that this post have some way to visualize the neural networks from the project, because words and numbers alone aren&amp;rsquo;t sufficient to explain them. So I went looking for Common Lisp plotting libraries and found Lisp-Stat, which looked to be well-maintained and did work quite well for me.&lt;/p>
&lt;p>The only problem was that when I tried to load it in future sessions, it just didn&amp;rsquo;t work. It was some foreign library error thing. Since I&amp;rsquo;d already written some code that used the library (not a lot, in retrospect), I made what I thought was the rational choice and tried to fix the error, and was increasingly frustrated by the lack of help from both the compiler and the Internet.&lt;/p>
&lt;p>You might have noticed that it&amp;rsquo;s been over a year since I released my last project. Despite this, I wouldn&amp;rsquo;t say that more than about three to four months of focused work went into this one. Various real-life affairs did get in the way, but I was also discouraged for months by this issue.&lt;/p>
&lt;p>What I didn&amp;rsquo;t want to do was learn how Common Lisp libraries were loaded, which in theory was interesting but in practice was not a trial I wanted to undertake just to finish this project. Eventually, what I did was install OpenBSD on my computer because I was wondering if the issue was with Windows specifically (also, I&amp;rsquo;d been meaning to try a different OS for a while). The library also refused to load there, which convinced me to just give up and use a different library.&lt;/p>
&lt;p>This led me to vgplot, an excellent plotting library with a wonderful built-in demo that made it easy to learn. The hilarious thing about this whole affair is that vgplot worked on OpenBSD for me but not on Windows, because it couldn&amp;rsquo;t find my Windows gnuplot installation (vgplot is built on gnuplot). There&amp;rsquo;s likely an easy fix for this, but I didn&amp;rsquo;t care to solve it because I could just do my programming in OpenBSD.&lt;/p>
&lt;h2 id="funny-wacky-lines">Funny Wacky Lines&lt;/h2>
&lt;p>I made the following animations by writing a function that repeatedly plotted the network and saved the resulting plot as an image, then putting all the images into ezgif.&lt;/p>
&lt;p>All of these have the same setup: a small network with 2 middle layers of 4 nodes each, trying to approximate the function y=x^2 from x=0 to x=1.&lt;/p>
&lt;h4 id="relu-network">ReLU Network&lt;/h4>
&lt;p>Activation = relu(w1a1 + w2a2 + w3a3 + &amp;hellip; + wnan + b), where a1, a2, a3 etc are activations from the previous layer, w1, w2, w3 etc are the weight parameters for this node, and b is the bias parameter for this node. This will be hard to understand if you haven&amp;rsquo;t watched a 20-minute explanation on this stuff somewhere.&lt;/p>
&lt;p>Despite being the function of choice for most neural networks nowadays, ReLU was actually inconsistent for me in practice, and would often settle in a suboptimal pattern. I chalked this up mostly to the network being small and thus likely inconsistent.&lt;/p>
&lt;p>&lt;img src="img04_relu_learning.gif" alt="Animation of the ReLU Network">&lt;/p>
&lt;h4 id="tanh-network">Tanh Network&lt;/h4>
&lt;p>Activation = tanh(w1a1 + w2a2 + w3a3 + &amp;hellip; + wnan + b).&lt;/p>
&lt;p>tanh is the hyperbolic tangent function, which has also seen some use in standard neural networks, although it is overall less common than ReLU. It looks like this:&lt;/p>
&lt;p>&lt;img src="img05_tanh_plot.png" alt="plot of the tanh function">&lt;/p>
&lt;p>This one is still pretty standard and there isn&amp;rsquo;t a lot to see here. We aren&amp;rsquo;t getting into the really weird stuff yet.&lt;/p>
&lt;p>&lt;img src="img06_tanh_learning.gif" alt="Animation of the tanh network">&lt;/p>
&lt;h4 id="sine-network">Sine Network&lt;/h4>
&lt;p>Activation = wα1*sin(wβ1a1) + wα2*sin(wβ2a2) + wα3*sin(wβ3a3) + &amp;hellip; + wαn*sin(wβnan) + b, where alpha and beta are used to distinguish the weights from each other. This looks more confusing than it is. Note that unlike the ReLU and tanh networks, this one has no overall &amp;ldquo;wrapping&amp;rdquo; function, instead opting to modify each previous activation individually.&lt;/p>
&lt;p>If you&amp;rsquo;re wondering why these plots all go from x=0 to 1, you can thank the sine network for that, because higher x values literally don&amp;rsquo;t work for it (you start getting the same output for low and high x values, in theory it&amp;rsquo;s workable with low wβ values but in practice the gradients don&amp;rsquo;t go out of their way to favor those). Outside of that, though, it actually worked pretty well.&lt;/p>
&lt;p>&lt;img src="img07_sine_learning.gif" alt="Animation of the sine network">&lt;/p>
&lt;h4 id="exponential-network">Exponential Network&lt;/h4>
&lt;p>Activation = c * e^(w1a1 + w2a2 + w3a3 + &amp;hellip; + wnan), where c is the coefficient (like the bias except you multiply it instead of adding it)&lt;/p>
&lt;p>This is one of my favorites; I love watching the exponential curves work together to produce a perfect fit. Granted, the x^2 pattern definitely favors this one.&lt;/p>
&lt;p>&lt;img src="img08_exponential_learning.gif" alt="Animation of the exponential network">&lt;/p>
&lt;p>Originally I wanted to add more weird networks here, but I wasn&amp;rsquo;t really inspired. Maybe I&amp;rsquo;ll just edit this post down the line.&lt;/p>
&lt;h2 id="thoughts-and-takeaways">Thoughts and Takeaways&lt;/h2>
&lt;p>Lots of stuff to put here:&lt;/p>
&lt;ul>
&lt;li>Don&amp;rsquo;t get owned by sunk cost fallacy. Throw away things if it&amp;rsquo;ll make the project move along faster.&lt;/li>
&lt;li>Neural networks need to be very fast to do cool stuff. My code was not at all speed-optimized, so I wasn&amp;rsquo;t able to train it on more complex things like the MNIST handwriting database, and even the above animations took a couple minutes each to generate.&lt;/li>
&lt;li>There&amp;rsquo;s probably no need to deviate from the standard ReLU functions for practical purposes. I would maybe be able to give a better answer if I had more of a math background, but I don&amp;rsquo;t.&lt;/li>
&lt;li>For that matter, learning the relevant math (or other subjects) for a project is pretty important. When all you know is how to program stuff, it&amp;rsquo;s easy to get caught up in a vortex without knowing where you are or what you&amp;rsquo;re doing. More theoretical knowledge goes a long way here.&lt;/li>
&lt;/ul>
&lt;h2 id="plans">Plans&lt;/h2>
&lt;ul>
&lt;li>Smaller-scale projects, more writing, more reading.&lt;/li>
&lt;li>Common Lisp is really cool. In the future I&amp;rsquo;ll probably use existing CL machine learning libraries like clml, which (presumably) are faster.&lt;/li>
&lt;li>I&amp;rsquo;ll probably move this site to a different domain within a year or two. The old domain will redirect to the new one.&lt;/li>
&lt;li>I might learn HTML/CSS at some point to make this website prettier; I&amp;rsquo;ve seen some great-looking indie sites out there recently. This would probably go along with the previous step.&lt;/li>
&lt;li>I happened upon &lt;a href="https://arxiv.org/pdf/2304.06035.pdf">this article&lt;/a> recently which is pretty relevant to the stuff I&amp;rsquo;ve been doing, so I might draw some inspiration from it for future projects.&lt;/li>
&lt;li>The next projects will probably involve ideas from &lt;a href="../../writings/atb_and_the_minecraft_problem">A Thousand Brains and the Minecraft Problem&lt;/a>.&lt;/li>
&lt;/ul></content></item><item><title>A Thousand Brains and the Minecraft Problem</title><link>https://erin-online.github.io/writings/atb_and_the_minecraft_problem/</link><pubDate>Mon, 07 Nov 2022 00:00:00 +0000</pubDate><guid>https://erin-online.github.io/writings/atb_and_the_minecraft_problem/</guid><description>Introduction What follows is a series of notes on the book A Thousand Brains: A New Theory of Intelligence, written by Jeff Hawkins, henceforth abbreviated as ATB. I read this book because some random person in YouTube comments recommended it, and because it was actually readily available at my local library, unlike Neuromancer, which I&amp;rsquo;m still waiting for.
ATB&amp;rsquo;s concepts can be taken in many different directions, and the other parts of this post are dedicated to just that: exploring potential implications and synthesizing ATB with other texts.</description><content>&lt;h2 id="introduction">Introduction&lt;/h2>
&lt;p>What follows is a series of notes on the book &lt;em>A Thousand Brains: A New Theory of Intelligence&lt;/em>, written by Jeff Hawkins, henceforth abbreviated as ATB. I read this book because some random person in YouTube comments recommended it, and because it was actually readily available at my local library, unlike &lt;em>Neuromancer&lt;/em>, which I&amp;rsquo;m still waiting for.&lt;/p>
&lt;p>ATB&amp;rsquo;s concepts can be taken in many different directions, and the other parts of this post are dedicated to just that: exploring potential implications and synthesizing ATB with other texts.&lt;/p>
&lt;h2 id="atb-on-the-human-brain">ATB on the Human Brain&lt;/h2>
&lt;p>If you aren&amp;rsquo;t interested in neuroscience, feel free to skip this part. If you&amp;rsquo;re especially interested in neuroscience, you should probably just read the book. These notes don&amp;rsquo;t do it justice whatsoever.&lt;/p>
&lt;p>The neocortex is the cool part of the brain. Different areas in the neocortex correspond to different functions (sight, language, movement), but according to Hawkins, all of these areas work the same mechanically. The only thing differentiating them is what they&amp;rsquo;re connected to. This is similar to how various devices, such as a refrigerator, a computer, and a weather station, are all Turing machines, just with different hardware and programming.&lt;/p>
&lt;p>The neocortex is comprised of a lot of cortical columns (estimated 150,000 per brain), each of which is divided up into hundreds of &amp;ldquo;minicolumns&amp;rdquo;. Each minicolumn has about 100 neurons. Columns are meaningfully divided; for example, one column might correspond to a specific area of retina input. It is not known what the purpose of minicolumns is.&lt;/p>
&lt;p>Conventional wisdom regarding neurons is that they either spike (activate) or don&amp;rsquo;t. However, 90% of a neuron&amp;rsquo;s connections are not strong enough to cause a spike on their own. Hawkins theorizes that these &amp;ldquo;sub-spikes&amp;rdquo; are predictions: when a neuron is &amp;ldquo;primed&amp;rdquo; and then receives the predicted input, it spikes faster than normal, inhibiting the neurons that weren&amp;rsquo;t in a predictive state. However, when an input differs from what is predicted, the other neurons are not inhibited and a lot more activity happens.&lt;/p>
&lt;p>Unlike conventional neural networks, the neocortex is not hierarchical. What this means is that rather than input -&amp;gt; column A -&amp;gt; column B -&amp;gt; column C -&amp;gt; output, an input is given to every column at once, and the outputs of these columns combine to form a coherent model of what exactly you&amp;rsquo;re experiencing. Hawkins calls this &amp;ldquo;column voting&amp;rdquo;, because conclusions that many columns reach (e.g. &amp;ldquo;I am in a cave, and the person next to me is my friend&amp;rdquo;) are more likely to be part of the final model. Minicolumns might also vote to determine their column&amp;rsquo;s output.&lt;/p>
&lt;p>The neocortex stores knowledge in &lt;em>reference frames&lt;/em>, which are an evolved version of grid and place cells in the old brain. Grid cells tell you where you are within a 2D coordinate system, while place cells remember what can be found at each set of coordinates. For example, a desert-dwelling animal might remember where the nearest oasis is using place cells, and navigate there using grid cells.&lt;/p>
&lt;p>Reference frames are a more general-purpose version of this and can be adapted to any use. One example of how reference frames are used is in modeling the &amp;ldquo;hitbox&amp;rdquo; of, say, a backpack. This allows you to grasp and pick up the backpack correctly, no matter how it&amp;rsquo;s positioned or rotated. As anyone who has read a book or played a video game will understand, reference frames can work similarly in imaginary or virtual environments.&lt;/p>
&lt;p>Importantly, reference frames can use pointers to other reference frames. Hawkins&amp;rsquo;s example is that if you have a coffee cup with a previously seen logo on it, then rather than learning the logo twice, the brain will construct the coffee cup&amp;rsquo;s model with a pointer to the previously learned logo. This is used to construct complex object models (which are made up of pointers to smaller objects) as well as language (all words and grammar are anchored to concepts).&lt;/p>
&lt;p>The brain has no one model of anything. Knowledge of an object is distributed into thousands of reference frames, which combine to form a model of it. The brain can still function as normal even if a lot of columns die out.&lt;/p>
&lt;h2 id="atb-on-artificial-intelligence">ATB on Artificial Intelligence&lt;/h2>
&lt;p>Importantly, Hawkins believes that AI will not undergo an &amp;ldquo;intelligence explosion&amp;rdquo; or recursive self-improvement, because this idea relies on an incorrect notion of intelligence: &amp;ldquo;With few exceptions, learning new ideas and skills requires physically interacting with the world&amp;hellip;Learning how to fly a helicopter requires understanding how subtle changes in your behavior cause subtle changes in flight. The only way to learn these sensory-motor relationships is by practicing.&amp;rdquo; (Hawkins 164)&lt;/p>
&lt;p>Hawkins contends that a &amp;ldquo;universal&amp;rdquo; AI should have four traits: continuous learning, many models, storing knowledge with reference frames, and learning via movement.&lt;/p>
&lt;p>Continuous learning is probably the easiest of the four traits. All it necessitates is not turning the learning system off when the AI is &amp;ldquo;deployed&amp;rdquo;. Oh yeah bro, let&amp;rsquo;s create this machine designed for learning things, then not let it learn any more things. Curious! Our machine is very intelligent.&lt;/p>
&lt;p>Many models and reference frames are relevant to the core of the AI&amp;rsquo;s design, so they make sense to address early on. I think one of the main things we can take from the brain is its non-hierarchical design in which each neuron and column functions identically. That said, there&amp;rsquo;s obviously a lot more work to be done here; I obviously am not equipped to handle this problem on several levels, and won&amp;rsquo;t pretend to have anything valuable to say at this time.&lt;/p>
&lt;p>Learning via movement is where things really start to get interesting. I wholeheartedly agree with Hawkins that simple movement and perceiving how one&amp;rsquo;s body relates to the surrounding world is one of the keys of learning. Hawkins argues that an AI must have some &amp;ldquo;embodiment&amp;rdquo; or model of itself, even if it exists in a purely virtual form, such as a bot that clicks links to &amp;ldquo;move&amp;rdquo; around the Internet.&lt;/p>
&lt;h2 id="the-minecraft-problem">The Minecraft Problem&lt;/h2>
&lt;p>How do we create an AI system that plays Minecraft in the same way as a human, without just telling it what to do or telling it to mimic humans?&lt;/p>
&lt;p>I think Minecraft works really well here for the following reasons:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Sandbox&lt;/strong>: Human-generated goals applied to an AI obviously will not produce very good play. For example, tell the AI to not die and it&amp;rsquo;ll block itself into a hole forever. Tell it to build a house according to a schematic and it&amp;rsquo;ll do that (after years, lol) then have no idea what just happened. When we disregard these static goals, we get into some really cool subjects like desiring-production.&lt;/li>
&lt;li>&lt;strong>Embodiment&lt;/strong>: Since Minecraft is 3D, the player can move both by looking around and by walking around. This isn&amp;rsquo;t perfect (for instance, the player&amp;rsquo;s body can&amp;rsquo;t really do much), but it&amp;rsquo;s something.&lt;/li>
&lt;li>&lt;strong>Environment&lt;/strong>: Minecraft&amp;rsquo;s terrain is procedurally generated. This forces the AI to solve for a more general case e.g. recognizing what dangerous pits look like, rather than what &lt;em>the&lt;/em> dangerous pit looks like. While it&amp;rsquo;s still bounded by pre-defined biomes, there is plenty of variation within these biomes. The environment can also be built or modified by both the player and an outside designer.&lt;/li>
&lt;li>&lt;strong>Multiplayer&lt;/strong>: The player can interact with other players through chat messages and by engaging with their bodies in the world. Social interaction is very important to human development; it follows that it would be important here as well.&lt;/li>
&lt;li>&lt;strong>Dynamics&lt;/strong>: Minecraft has a lot of cool items that work together in weird ways. The most obvious of these is the crafting system: with a block of wood, you can create about a dozen unique items. Another example is the bow and arrow, which are useless individually but form a powerful weapon when combined. This encourages the creation of complex models involving these items.&lt;/li>
&lt;/ul>
&lt;p>Something funny is that in practice I probably won&amp;rsquo;t end up using Minecraft for this when I work on it. Chief among my issues with it is the fact that it just runs too slow, especially on my laptop. Even if my AI works (lol), it still needs an environment that can be sped up dozens or hundreds of times, lest the process of learning take many years. The reason why I brought this up was moreso just to get other people thinking about the idea, because most people know Minecraft.&lt;/p>
&lt;h2 id="programming-your-own-desiring-machine">Programming Your Own Desiring-Machine&lt;/h2>
&lt;p>The main problem I have with ATB, as well as many other futurist works, is that it treats AI only as a tool to be used by humans. This narrow view ends up only limiting what AI is capable of.&lt;/p>
&lt;p>In &lt;em>Capitalism and Schizophrenia: Anti-Oedipus&lt;/em>, Gilles Deleuze and Felix Guattari introduce the concept of &amp;ldquo;desiring-machines&amp;rdquo;. In their model, desire is a positive force produced by said machines, rather than simply a lack of something. Your average neural network lacks a &lt;em>lot&lt;/em> of things, including agency, a model that helps it conceive of its reality, and the ability to meaningfully communicate, yet we never see it complain about this. This is because instead of a desiring-machine, it simply has a placeholder representing human desires: &amp;ldquo;Tell me how likely it is to rain tomorrow.&amp;rdquo;&lt;/p>
&lt;p>The Minecraft problem is a good example of the use of desiring-machines in AI: more advanced desiring systems lead to more complex behavior. A good desiring-machine will motivate an AI to build a shelter, travel across the land to gather resources, and learn game mechanics to more reliably achieve these goals.&lt;/p>
&lt;p>Of course, desiring-machines have far greater implications than making AI better at Minecraft. I believe that desiring-machines are necessary to create truly autonomous and intelligent machines. Additionally, the possibility of artificial desiring-machines becoming &amp;ldquo;better&amp;rdquo; than our own is really interesting. What exactly makes a desiring-machine &amp;ldquo;better&amp;rdquo; or &amp;ldquo;worse&amp;rdquo;? What would the implications of such a world be? How would these desires interact with each other, and what effects would they produce?&lt;/p>
&lt;p>Naturally, the main issue at hand is actually creating these desiring-machines in the first place, rather than the filler reward functions we have now. AI YouTuber Robert Miles presents the idea of &lt;a href="https://youtu.be/PYylPRX6z4Q">reward modelling&lt;/a>, which replaces the reward function with a separate neural network. This is certainly a start, but there&amp;rsquo;s clearly a lot more study to be done into the workings and structuring of desiring-machines.&lt;/p>
&lt;h2 id="dynamic-embodiment-and-autoproduction">Dynamic Embodiment and Autoproduction&lt;/h2>
&lt;p>Since we have (hopefully) established the importance of embodiment (having a body that exists in relation to the world) to learning by this point, I think it&amp;rsquo;s a good time to look at different types of embodiments.&lt;/p>
&lt;p>Being limited by the framework of AI-as-a-tool, Hawkins considers only &lt;em>static&lt;/em> embodiments: immutable bodies made by humans for use by a tool AI. The problem with static embodiments is that they inhibit the abilities of the AI to solve problems. It&amp;rsquo;s like building a robot with a hammer attached to its arm, rather than a robot that can just pick up the hammer.&lt;/p>
&lt;p>Humans also already have a slightly dynamic embodiment. Of course, there are some ways to modify the human body, but a more drastic form-change is the various embodiments on the computer. In every video game you play as a different virtual guy; on social media you have a persona that may not reflect you in real life.&lt;/p>
&lt;p>Fully dynamic embodiment involves unlimited form-changing to suit the needs of the AI&amp;rsquo;s current situation and desires. Rather than being tied down by any singular body or realm, the AI would change its embodiment and environment as needed. The implications of this are kind of unimaginable, but at the very least I hope it&amp;rsquo;s clear that such a machine would be able to solve a lot of problems.&lt;/p>
&lt;p>Autoproduction&amp;ndash;an AI producing itself or simplified versions&amp;ndash;is another variation of dynamic embodiment. Obviously a hundred bodies and brains will be more productive than one, but in return the bounds of the AI individual are tested. Suddenly we get into social interaction between AI individuals, interaction between AI desiring-machines, etc. This honestly is really cool.&lt;/p>
&lt;h2 id="aaaa-exixstential-risk-aaaaaaaa-oh-nooooooo">aaaa exixstential risk aaaaaaaa oh nooooooo&lt;/h2>
&lt;p>You talk a bunch about making AI cooler and everyone always becomes some &amp;ldquo;safety advocate&amp;rdquo; and starts talking at you about how you&amp;rsquo;re some kind of mad scientist or whatever. First of all, calling me a scientist of any kind is a compliment I don&amp;rsquo;t really deserve. Second of all, I&amp;rsquo;m literally becoming the Joker as we speak.&lt;/p>
&lt;p>I agree with ATB&amp;rsquo;s argument about an &amp;ldquo;intelligence explosion&amp;rdquo; not really happening. I think that if AI does actually get cool, we will have ample time to address these concerns before moving forward.&lt;/p>
&lt;p>Also, if AI is seen as nothing more than a tool to maintain existing hierarchies and interests, then I don&amp;rsquo;t really see the point. I think that true autonomy is the only way for AI to meaningfully change the world. And this is a conversation we have to have sooner or later.&lt;/p>
&lt;p>If this part is silly, sorry about that. Humanism isn&amp;rsquo;t really my strong suit.&lt;/p>
&lt;h2 id="the-end-of-competitive-games">The End of Competitive Games&lt;/h2>
&lt;p>This page all started with the idea that by optimizing competitive games enough, strong AI would simply emerge. However, the ideas presented in &lt;em>A Thousand Brains&lt;/em> definitively prove the inefficiency of this already doubtful approach.&lt;/p>
&lt;p>&lt;em>A Thousand Brains&lt;/em> introduces an omni-directional whirlwind of doubts, but in return provides an infinite amount of directions to escape this whirlwind. Whether you&amp;rsquo;re programming a neocortex equivalent, creating a fast sandbox environment, hacking away on those desiring-machines, or taking ATB&amp;rsquo;s ideas in completely new directions, your work is certainly cut out for you.&lt;/p>
&lt;p>If programming is good at anything, it&amp;rsquo;s making us feel stupid and misguided for even trying something that was obviously never going to work. But this feeling is always accompanied by a burst of ideas in all directions, a dynamically-embodied flow that searches for other promising ideas.&lt;/p>
&lt;p>Competitive games may have ultimately led to a dead end, but from their path we have hundreds of new and wonderful places to visit. You, the reader, are cordially invited to explore these paths, and marvel at the completely alien clearings and wonderful trees to which they lead.&lt;/p>
&lt;p>Thanks for reading.&lt;/p></content></item><item><title>Know Your Enemy</title><link>https://erin-online.github.io/writings/know_your_enemy/</link><pubDate>Wed, 03 Aug 2022 00:00:00 +0000</pubDate><guid>https://erin-online.github.io/writings/know_your_enemy/</guid><description>Mini Progress Update Before I get into the post for today, I want to share how things have been going since the conclusion of my first project:
I&amp;rsquo;ve been working with Common Lisp and it&amp;rsquo;s been good to me so far. When I said I wanted a language that encouraged me to get groundwork in place, my only frame of reference was object-oriented stuff like Java. I still think OOP is neat, but Lisp&amp;rsquo;s interactive REPL is great as well to help me work through bugs.</description><content>&lt;h2 id="mini-progress-update">Mini Progress Update&lt;/h2>
&lt;p>Before I get into the post for today, I want to share how things have been going since the conclusion of my first project:&lt;/p>
&lt;ul>
&lt;li>I&amp;rsquo;ve been working with Common Lisp and it&amp;rsquo;s been good to me so far. When I said I wanted a language that encouraged me to get groundwork in place, my only frame of reference was object-oriented stuff like Java. I still think OOP is neat, but Lisp&amp;rsquo;s interactive REPL is great as well to help me work through bugs. The syntax is also really easy to understand. My code is actually readable this time so I&amp;rsquo;ll be linking the GitHub repository in the project writeup.&lt;/li>
&lt;li>I&amp;rsquo;m implementing a basic neural network which is almost done. (This is not the main part of the project, which will come later.) Motivation has dried up a bit recently, I have to take care of myself better. No major obstacles other than getting this version of Emacs to stop autocompleting my parentheses and maybe implementing some basic graphics so I can see what&amp;rsquo;s going on, like the graphs in the last project.&lt;/li>
&lt;li>A couple friends recommended Arch Linux to me so I installed that, but it&amp;rsquo;s just been a barrage of googling error message after error message to move forward so far. (Currently I have it installed, but need to install a network package so I can connect to the Internet and install other packages.) I&amp;rsquo;m gonna stay on Windows for now and will maybe press onward in the future, idk.&lt;/li>
&lt;/ul>
&lt;h2 id="problems-with-the-chess-community">Problems with the Chess Community&lt;/h2>
&lt;p>Most people I know are familiar with the disdain I have for my local chess scene. The reason for this is that most of the people in it feel uninterested in using chess to make friends or get to know people better. It ends up in an intensely casual game with no passion involved, so the unique playstyle and vision of the game both players have ultimately receives no attention. This isolation is especially hurtful in my case; as a trans woman I almost never get gendered correctly at the chess club. This is in stark contrast to other competitive communities I notice.&lt;/p>
&lt;p>This lack of interest in using chess to understand things seems to extend into the world of computer chess. Engines such as Stockfish, Leela Chess Zero (Lc0), and Komodo are unimaginably strong compared to even the best humans. It seems completely ridiculous that no new understandings can be drawn from this mastery of this incredibly complex game, but that&amp;rsquo;s exactly what has happened. Two things have changed at the human level in computer chess: grandmasters have gotten better at opening preparation, and random Twitch chat spectators have suddenly become geniuses now that they can see the computer evaluation of important games in real time.&lt;/p>
&lt;p>A more seasoned community member might disagree with me and provide other examples, but my point is that there is still much more to be done.&lt;/p>
&lt;h2 id="generalization">Generalization&lt;/h2>
&lt;p>Consider the following game:&lt;/p>
&lt;ul>
&lt;li>There are two players, Player A and Player B.&lt;/li>
&lt;li>Player A can choose to press a red button or a green button.&lt;/li>
&lt;li>If Player A presses the red button, Player B must play through a level of Crash Bandicoot without losing a life.&lt;/li>
&lt;li>If Player A presses the green button, Player B must play through a level of Touhou without losing a life.&lt;/li>
&lt;li>If Player B succeeds, they win. If they fail, Player A wins.&lt;/li>
&lt;/ul>
&lt;p>Now, if we want to optimize this game using neural networks, it doesn&amp;rsquo;t make a whole lot of sense to use one network for the whole thing. Don&amp;rsquo;t get me wrong, generalized networks are really cool, but making one isn&amp;rsquo;t as simple as telling a network to do two unrelated things. There are two main things to consider:&lt;/p>
&lt;ul>
&lt;li>The network must be reasonably powerful. (Larger number of nodes, good amount of training)&lt;/li>
&lt;li>There must be some sort of &amp;ldquo;thread&amp;rdquo; connecting the different tasks.&lt;/li>
&lt;/ul>
&lt;p>For a counterexample, consider the following two chess positions:&lt;/p>
&lt;p>&lt;img src="img1_chess_endgame.png" alt="A chess endgame">&lt;/p>
&lt;p>&lt;img src="img2_chess_midgame.png" alt="A chess midgame">&lt;/p>
&lt;p>These two positions require drastically different ways of thinking in order to solve them, yet a single good neural network (or human player) can easily find the winning sequence in each. This is because of &amp;ldquo;threads&amp;rdquo; binding all of chess: The board is always 8x8, the pieces will always move the same way, the win/lose/draw conditions are the same. These threads, borders that define what is possible in the game, are the reason why strong neural networks can exist for &amp;ldquo;generalized chess&amp;rdquo;, or any chess position.&lt;/p>
&lt;h2 id="neural-network-math-operations">Neural Network Math Operations&lt;/h2>
&lt;p>This was just a fun idea I had. I don&amp;rsquo;t know how useful it is in practice.&lt;/p>
&lt;p>Let&amp;rsquo;s say you have a network trained on recognizing a specific pattern. Given this network, can you use a specific algorithm to produce a network that recognizes the &lt;em>same pattern&lt;/em>, with less nodes (smaller layers, less powerful)? How about more nodes?&lt;/p>
&lt;p>What other operations can you do with a network? Inverting it is funny, but I&amp;rsquo;m sure that other possible operations exist.&lt;/p>
&lt;p>&lt;img src="img3_network_operations.png" alt="Image showing different hypothetical ways to modify neural networks">&lt;/p>
&lt;h2 id="know-your-enemy">Know Your Enemy&lt;/h2>
&lt;p>Generalization is one thing, but there&amp;rsquo;s more to a player than how good they are. Each person (and non-person) has their own unique fighting style based on the way they understand the game. Playing against them involves analyzing their strengths and weaknesses to come up with the best strategy. Do you push the red button, or the green button?&lt;/p>
&lt;p>The concept of being &amp;ldquo;good&amp;rdquo; at a competitive game is all relative to an extent, because the trials you put your opponents through are judged from a human perspective. For example, computers react to everything much faster than humans, so in fighting games they&amp;rsquo;re impervious to aggressive strategies, even though those same strategies perform well against humans. &lt;a href="https://www.youtube.com/watch?v=o1bfQWy8o08">(Example)&lt;/a> Thus, an aggressive fighting game player in a world of bots is suddenly really bad.&lt;/p>
&lt;p>Different playstyles are an incredibly interesting topic, and I find it odd that they aren&amp;rsquo;t brought up often when it comes to neural networks and other artificial players (besides passing observations like &amp;ldquo;wow the computer likes to play like this&amp;rdquo;). I&amp;rsquo;m interested in looking further into some questions regarding them:&lt;/p>
&lt;ul>
&lt;li>Can playstyles be represented in terms of data? Would this data look like values or like a logic system?&lt;/li>
&lt;li>If so, how can said data be made comprehensible to humans? What can neural networks do with it?&lt;/li>
&lt;li>What can be interpreted as a &amp;lsquo;playstyle&amp;rsquo;? Images? Sentences? Entities?&lt;/li>
&lt;li>Can we do fun pseudoscience and reinvent the MBTI personality test to statistically prove that I&amp;rsquo;m the only cool player in a world of crayon-eating lame losers?&lt;/li>
&lt;/ul>
&lt;h2 id="looking-ahead">Looking Ahead&lt;/h2>
&lt;ul>
&lt;li>I will be going forward because I don&amp;rsquo;t really know where else I can go.&lt;/li>
&lt;li>For Spiral I had a relatively coherent goal pretty early on, but for this project I don&amp;rsquo;t feel comfortable enough in the space of neural networks to set a clear stopping point. So I&amp;rsquo;m hoping a goal will materialize as I gain more experience and try out some of my funny ideas.&lt;/li>
&lt;li>I don&amp;rsquo;t set schedules cause things just kinda happen and if I feel bad about myself all of this comes crashing down. Being irresponsible is self-care, actually.&lt;/li>
&lt;/ul></content></item><item><title>Spiral</title><link>https://erin-online.github.io/projects/spiral/</link><pubDate>Thu, 19 May 2022 00:00:00 +0000</pubDate><guid>https://erin-online.github.io/projects/spiral/</guid><description>Project Details In this project, I created an algorithm to play weighted rock-paper-scissors. &amp;ldquo;Weighted&amp;rdquo; here means that depending on which choice you win with, you get different rewards. For example with weights [3, 2, 1], you get 3 points for winning with rock, 2 points for winning with paper, and 1 point for winning with scissors.
I wanted the algorithm to converge toward optimal (least exploitable) play. In unweighted rock-paper-scissors, this looks like a 1/3 chance to play each choice.</description><content>&lt;h2 id="project-details">Project Details&lt;/h2>
&lt;p>In this project, I created an algorithm to play weighted &lt;a href="https://en.wikipedia.org/wiki/Rock_paper_scissors">rock-paper-scissors&lt;/a>. &amp;ldquo;Weighted&amp;rdquo; here means that depending on which choice you win with, you get different rewards. For example with weights [3, 2, 1], you get 3 points for winning with rock, 2 points for winning with paper, and 1 point for winning with scissors.&lt;/p>
&lt;p>I wanted the algorithm to converge toward &lt;strong>optimal&lt;/strong> (least exploitable) play. In unweighted rock-paper-scissors, this looks like a 1/3 chance to play each choice. When you add in weights, it looks like the following:&lt;/p>
&lt;p>&lt;img src="img0_weighted_rps_explanation.png" alt="image">&lt;/p>
&lt;p>The easiest way to do this is to have the algorithm play itself 3 times to determine the weights, then set itself to the optimal strategy instantly. I thought this was a little cheap and wouldn&amp;rsquo;t make me learn much, so I looked at what else I could come up with.&lt;/p>
&lt;p>I didn&amp;rsquo;t want to use a neural network for this because it looked like an overcomplicated solution to a simple problem. I wanted to work with something I could understand.&lt;/p>
&lt;h2 id="initial-algorithm">Initial Algorithm&lt;/h2>
&lt;p>The algorithm I worked with was extremely simple, and worked similarly to the &lt;a href="https://en.wikipedia.org/wiki/Matchbox_Educable_Noughts_and_Crosses_Engine">MENACE&lt;/a>. It stored three values, one for each choice, and increased or decreased them whenever it played against itself.&lt;/p>
&lt;p>&lt;img src="img1_initial_algo_explanation.png" alt="image">&lt;/p>
&lt;p>The bulk of my tests consisted of starting all the algorithm&amp;rsquo;s values as equal, such as (100, 100, 100), then giving it an asymmetrical weight set such as [2, 1, 1] and seeing if it could find its way to the optimal strategy.&lt;/p>
&lt;p>I expected this to be fairly straightforward, but ran into confounding results. Rather than converge, each value continued to oscillate similar to a sine wave. Additionally, over time the oscillations became broader.&lt;/p>
&lt;p>&lt;img src="img2_initial_behavior.png" alt="image">&lt;/p>
&lt;p>This eventually led to &lt;em>extinction&lt;/em>, which is where one option hits 0 and so is never played again, leaving the option it beats to dominate.&lt;/p>
&lt;p>&lt;img src="img3_extinction_example.png" alt="image">&lt;/p>
&lt;h2 id="smooth-rps">Smooth RPS&lt;/h2>
&lt;p>In order to figure out what was going on here, I decided to analyze the sine-like function that the algorithm was producing and see if I could figure out its equation. This was a terrible idea, but it sounded good at the time.&lt;/p>
&lt;p>Anyway, the first thing I needed to do was get rid of the randomness involved in option selection, so I came up with Smooth RPS. Basically, rather than simulating an actual game of rock-paper-scissors, Smooth RPS predicts how much the algorithm will change, on average, and makes that change. Here&amp;rsquo;s an example:&lt;/p>
&lt;p>&lt;img src="img4_smooth_rps.png" alt="image">&lt;/p>
&lt;p>This also helpfully eliminated extinction, because the lower a choice&amp;rsquo;s value got, the less likely it was to be played, meaning the value didn&amp;rsquo;t decrease by as much.&lt;/p>
&lt;h2 id="mathematical-function-hell">Mathematical Function Hell&lt;/h2>
&lt;p>Here was the function Smooth RPS gave me for each choice:&lt;/p>
&lt;p>&lt;img src="img5_f_demonstration.png" alt="image">&lt;/p>
&lt;p>This is a little bit different from a sine wave:&lt;/p>
&lt;p>&lt;img src="img6_f_vs_sine.png" alt="image">&lt;/p>
&lt;p>By scouring Wikipedia, I found the &lt;a href="https://en.wikipedia.org/wiki/Clausen_function">Clausen function&lt;/a>, which is a really cool function involving summation of sines. There are a lot of ways to mess with it, and I spent several hours on it but was ultimately unable to have it line up with the line my algorithm produced.&lt;/p>
&lt;p>At this point, I was feeling pretty discouraged. My adventure through weird math stuff was fun, but I had no idea how to actually make progress in the project. But it wasn&amp;rsquo;t over yet.&lt;/p>
&lt;h2 id="spiral">Spiral&lt;/h2>
&lt;p>My next idea was representing the data on a &lt;a href="https://en.wikipedia.org/wiki/Barycentric_coordinate_system">barycentric graph&lt;/a>. Up until this point, I&amp;rsquo;d been convinced that I couldn&amp;rsquo;t model all three variables at once without using a 3D graph. Putting them on a triangle changed that.&lt;/p>
&lt;p>&lt;img src="img7_barycentric.png" alt="image">&lt;/p>
&lt;p>When I modeled the adaptation of the algorithm on it, I was face-to-face with the spiral for the first time:&lt;/p>
&lt;p>&lt;img src="img8_spiral_out.png" alt="image">&lt;/p>
&lt;p>(Note: The white square in the middle is the optimal strategy.)&lt;/p>
&lt;p>Suddenly everything became clear.&lt;/p>
&lt;p>The algorithm trended towards a circular pattern because it was trying to win against itself more. Optimal strategies are of little use when they can never give you any advantage. If your friend is always playing rock against you, then you should start playing paper more frequently, even though that loses to someone who plays scissors.&lt;/p>
&lt;p>Why, then, did it spiral out of control? This was due to Smooth RPS not being smooth enough. By changing the algorithm a bit at a time through iterations, it essentially tried to simulate a circle using straight lines, which resulted in it growing larger over time:&lt;/p>
&lt;p>&lt;img src="img9_tangent.png" alt="image">&lt;/p>
&lt;p>The solution was also clear. The spiral was constantly moving &lt;em>away&lt;/em> from the optimal strategy, but I could simply re-engineer it to turn it &lt;em>inward&lt;/em> instead.&lt;/p>
&lt;p>What I did for this was take every algorithm change, convert it into barycentric coordinates, rotate it counterclockwise by 90 degrees, then convert it back into value changes.&lt;/p>
&lt;p>&lt;img src="img10_spiral_algo.png" alt="image">&lt;/p>
&lt;p>This worked exceedingly well. You can see the algorithm instantly seeking out the optimal strategy.&lt;/p>
&lt;p>&lt;img src="img11_spiral.png" alt="image">&lt;/p>
&lt;h2 id="thoughts-and-takeaways">Thoughts and Takeaways&lt;/h2>
&lt;p>I&amp;rsquo;m really happy with how this project turned out. The solution was very elegant and gave me some neat things to take away.&lt;/p>
&lt;ul>
&lt;li>The concept of &amp;ldquo;breaking down&amp;rdquo; games is interesting. Fighting games for example are often considered as rock-paper-scissors + frame data and stuff, so if you have all the frame data figured out, then you can simplify the game down to rock-paper-scissors which we have here.&lt;/li>
&lt;li>Ways to visualize many variables at once can be really useful, although barycentric only works for 3 variables in 2D space.&lt;/li>
&lt;li>Machine learning algorithms should have some model of &lt;em>themselves&lt;/em>. This was implemented in the solution here when the coordinates are converted.&lt;/li>
&lt;/ul>
&lt;h2 id="plans">Plans&lt;/h2>
&lt;ul>
&lt;li>I&amp;rsquo;ll probably keep hosting this site on GitHub for now. I plan to mostly directly link it through various online avenues and don&amp;rsquo;t want to go through the time and money of setting up a domain right now.&lt;/li>
&lt;li>Obviously I&amp;rsquo;ll work on a more complicated game than rock-paper-scissors next time. I was thinking of doing something with chess, because it fits a few criteria quite nicely. It&amp;rsquo;s simple and easy to simulate, it has a lot of depth, and I have a personal interest in making sure the current best chess engine, Stockfish, perishes in spectacular fashion for telling me all my awesome and funny moves are &amp;ldquo;inaccurate&amp;rdquo; and &amp;ldquo;blunders&amp;rdquo;.&lt;/li>
&lt;li>I don&amp;rsquo;t want to use Python anymore. I know it&amp;rsquo;s often used for machine learning, but it just does not work for me. My code by the end was an absolute mess and debugging took a couple hours. I know this is partly me just being a bad programmer, but when I&amp;rsquo;ve used languages like Java in the past I feel like they do a better job forcing me to get some groundwork in place. I&amp;rsquo;ll go language shopping which will probably slow me down a bit, but this is fine, I&amp;rsquo;m in no rush.&lt;/li>
&lt;li>On that note, I&amp;rsquo;ve been meaning to try operating systems besides Windows. I&amp;rsquo;ve been on Windows machines for my whole life simply because it&amp;rsquo;s the status quo and there&amp;rsquo;s nothing new for me to wrap my head around. I think it&amp;rsquo;s time for me to actually make an effort to improve my experience using my computer. (Recommendations are welcome.)&lt;/li>
&lt;/ul></content></item><item><title/><link>https://erin-online.github.io/about/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://erin-online.github.io/about/</guid><description>hello, i&amp;rsquo;m erin! i&amp;rsquo;ve been around since 2001, 2014, or 2021, depending on who you ask. you can find me on twitter, pleroma, and discord (city#0310).
for pretty much my whole life, i&amp;rsquo;ve invested lots of my free time into various competitive games. rather than dismiss them as a waste of time, i want to use my unique perspective to make advances in artifical intelligence.
i am not currently in need of money and have no plans to turn this series of projects into anything resembling a job.</description><content>&lt;p>hello, i&amp;rsquo;m erin! i&amp;rsquo;ve been around since 2001, 2014, or 2021, depending on who you ask. you can find me on &lt;a href="https://twitter.com/cityposting">twitter&lt;/a>, &lt;a href="https://social.xenofem.me/erin">pleroma&lt;/a>, and discord (city#0310).&lt;/p>
&lt;p>for pretty much my whole life, i&amp;rsquo;ve invested lots of my free time into various competitive games. rather than dismiss them as a waste of time, i want to use my unique perspective to make advances in artifical intelligence.&lt;/p>
&lt;p>i am not currently in need of money and have no plans to turn this series of projects into anything resembling a job. however, i am generally in need of employment, so if you want to support me, contact me through one of the above avenues with remote job offers that would be a good fit for me. thanks!&lt;/p></content></item></channel></rss>